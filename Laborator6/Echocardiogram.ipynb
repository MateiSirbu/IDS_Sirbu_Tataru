{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echocardiogram. Modele de clasificare\n",
    "\n",
    "Sîrbu Matei-Dan, _grupa 10LF383_\n",
    "\n",
    "<i>Sursă dataset:</i> http://archive.ics.uci.edu/ml/datasets/Echocardiogram\n",
    "\n",
    "<i>Synopsis:</i> Datasetul _Echocardiogram_ cuprinde 132 de înregistrări de date obținute din ecocardiografiile unor pacienți care au suferit un atac de cord în trecut. Datele sunt utilizate pentru a prezice dacă un pacient va supraviețui cel puțin un an după un atac de cord.\n",
    "\n",
    "În cele ce urmează, atributul **alive-at-1** este reprezentată de y, iar coloanele **survival, still-alive, age-at-heart-attack, pericardial-effusion, fractional-shortening, epss, lvdd, wall-motion-score, wall-motion-index, mult**, de X.\n",
    "\n",
    "_Verbose attribute info:_\n",
    "1. survival -- the number of months patient survived (has survived, if patient is still alive). Because all the patients had their heart attacks at different times, it is possible that some patients have survived less than one year but they are still alive. Check the second variable to confirm this. Such patients cannot be used for the prediction task mentioned above.\n",
    "2. still-alive -- a binary variable. 0=dead at end of survival period, 1 means still alive\n",
    "3. age-at-heart-attack -- age in years when heart attack occurred\n",
    "4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart. 0=no fluid, 1=fluid\n",
    "5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal\n",
    "6. epss -- E-point septal separation, another measure of contractility. Larger numbers are increasingly abnormal.\n",
    "7. lvdd -- left ventricular end-diastolic dimension. This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.\n",
    "8. wall-motion-score -- a measure of how the segments of the left ventricle are moving\n",
    "9. wall-motion-index -- equals wall-motion-score divided by number of segments seen. Usually 12-13 segments are seen in an echocardiogram. Use this variable INSTEAD of the wall motion score.\n",
    "10. mult -- a derivate var which can be ignored\n",
    "11. name -- the name of the patient (I have replaced them with \"name\")\n",
    "12. group -- meaningless, ignore it\n",
    "13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year. 1 means patient was alive at 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset overview:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>mult</th>\n",
       "      <th>name</th>\n",
       "      <th>group</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>9</td>\n",
       "      <td>4.600</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>6</td>\n",
       "      <td>4.100</td>\n",
       "      <td>14</td>\n",
       "      <td>1.700</td>\n",
       "      <td>0.588</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>4</td>\n",
       "      <td>3.420</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253</td>\n",
       "      <td>12.062</td>\n",
       "      <td>4.603</td>\n",
       "      <td>16</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.788</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160</td>\n",
       "      <td>22</td>\n",
       "      <td>5.750</td>\n",
       "      <td>18</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.571</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>12.9</td>\n",
       "      <td>4.72</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.47</td>\n",
       "      <td>11</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.714</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.05</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.857</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>16.1</td>\n",
       "      <td>4.36</td>\n",
       "      <td>15</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.786</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.409</td>\n",
       "      <td>0.786</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival still-alive age-at-heart-attack  pericardial-effusion  \\\n",
       "0         11           0                  71                     0   \n",
       "1         19           0                  72                     0   \n",
       "2         16           0                  55                     0   \n",
       "3         57           0                  60                     0   \n",
       "4         19           1                  57                     0   \n",
       "..       ...         ...                 ...                   ...   \n",
       "127      7.5           1                  64                     0   \n",
       "128       41           0                  64                     0   \n",
       "129       36           0                  69                     0   \n",
       "130       22           0                  57                     0   \n",
       "131       20           0                  62                     0   \n",
       "\n",
       "    fractional-shortening    epss   lvdd wall-motion-score wall-motion-index  \\\n",
       "0                   0.260       9  4.600                14                 1   \n",
       "1                   0.380       6  4.100                14             1.700   \n",
       "2                   0.260       4  3.420                14                 1   \n",
       "3                   0.253  12.062  4.603                16             1.450   \n",
       "4                   0.160      22  5.750                18             2.250   \n",
       "..                    ...     ...    ...               ...               ...   \n",
       "127                  0.24    12.9   4.72                12                 1   \n",
       "128                  0.28    5.40   5.47                11              1.10   \n",
       "129                  0.20    7.00   5.05              14.5              1.21   \n",
       "130                  0.14    16.1   4.36                15              1.36   \n",
       "131                  0.15       0   4.51              15.5             1.409   \n",
       "\n",
       "      mult  name group alive-at-1  \n",
       "0        1  name     1          0  \n",
       "1    0.588  name     1          0  \n",
       "2        1  name     1          0  \n",
       "3    0.788  name     1          0  \n",
       "4    0.571  name     1          0  \n",
       "..     ...   ...   ...        ...  \n",
       "127  0.857  name     ?          ?  \n",
       "128  0.714  name     ?          ?  \n",
       "129  0.857  name     ?          ?  \n",
       "130  0.786  name     ?          ?  \n",
       "131  0.786  name     ?          ?  \n",
       "\n",
       "[132 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = ['survival', 'still-alive', 'age-at-heart-attack', 'pericardial-effusion', 'fractional-shortening', 'epss', 'lvdd', 'wall-motion-score', 'wall-motion-index', 'mult', 'name', 'group', 'alive-at-1']\n",
    "data_echo = pd.read_csv(\"./Datasets/echocardiogram.csv\", names=header)\n",
    "display(HTML(\"<i>Dataset overview:</i>\"))\n",
    "display(data_echo)\n",
    "# ignoring irrelevant columns, as per verbose attribute info:\n",
    "del data_echo['mult']\n",
    "del data_echo['name']\n",
    "del data_echo['group']\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum se poate observa în subsolul tabelului, despre unii pacienți nu se știe dacă au supraviețuit la 1 an de la atacul de cord, exact informația pe care vrem să o prezicem după antrenarea modelelor de clasificare. Aceste ecocardiograme se vor elimina din dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Last records in sanitized dataset:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.52</td>\n",
       "      <td>18.16</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5.49</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.29</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>.75</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>40</td>\n",
       "      <td>6.23</td>\n",
       "      <td>14</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.42</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival still-alive age-at-heart-attack  pericardial-effusion  \\\n",
       "104     1.25           1                  63                     0   \n",
       "105       24           0                  59                     0   \n",
       "106       25           0                  57                     0   \n",
       "108      .75           1                  78                     0   \n",
       "109        3           1                  62                     0   \n",
       "\n",
       "    fractional-shortening  epss  lvdd wall-motion-score wall-motion-index  \\\n",
       "104                  0.30   6.9  3.52             18.16              1.51   \n",
       "105                  0.17  14.3  5.49              13.5              1.50   \n",
       "106                 0.228   9.7  4.29                11                 1   \n",
       "108                  0.23    40  6.23                14               1.4   \n",
       "109                  0.26   7.6  4.42                14                 1   \n",
       "\n",
       "    alive-at-1  \n",
       "104          1  \n",
       "105          0  \n",
       "106          0  \n",
       "108          1  \n",
       "109          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_echo = data_echo[(data_echo['alive-at-1'] == '0') | (data_echo['alive-at-1'] == '1')]\n",
    "display(HTML(\"<i>Last records in sanitized dataset:</i>\"))\n",
    "data_echo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De asemenea, unele înregistrări au valori lipsă, valori pe care va trebui să le improvizăm prin _missing value imputation_. Pentru a decide modul în care vom imputa date, trebuie să aflăm modul în care lipsesc datele; există trei tipuri de _missingness mechanisms_: \n",
    "- Missingness completely at random\n",
    "- Missingness at random\n",
    "- Missingness that depends on unobserved predictors\n",
    "- Missingness that depends on the missing value itself.\n",
    "\n",
    "# TODO: pick best data imputation technique and explain choice; 'mean' strategy tested below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset extract with missing values:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.590</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.5</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>21.300</td>\n",
       "      <td>6.290</td>\n",
       "      <td>17</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>2.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survival still-alive age-at-heart-attack  pericardial-effusion  \\\n",
       "43       46           0                  56                     0   \n",
       "46     19.5           1                  81                     0   \n",
       "47       20           1                  59                     0   \n",
       "48     0.25           1                  63                     1   \n",
       "50        2           1                  56                     1   \n",
       "51        7           1                  61                     1   \n",
       "\n",
       "   fractional-shortening    epss   lvdd wall-motion-score wall-motion-index  \\\n",
       "43                 0.330     NaN  3.590                14                 1   \n",
       "46                 0.120     NaN    NaN                 9             1.250   \n",
       "47                 0.030  21.300  6.290                17             1.310   \n",
       "48                   NaN     NaN    NaN                23             2.300   \n",
       "50                 0.040      14      5               NaN               NaN   \n",
       "51                 0.270     NaN    NaN                 9             1.500   \n",
       "\n",
       "   alive-at-1  \n",
       "43          0  \n",
       "46          0  \n",
       "47          0  \n",
       "48          1  \n",
       "50          1  \n",
       "51          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_echo.replace(to_replace='?', value=np.nan, inplace=True)\n",
    "display(HTML(\"<i>Dataset extract with missing values:</i>\"))\n",
    "data_echo[33:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset extract with values imputed:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>46.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>12.576636</td>\n",
       "      <td>3.590000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>19.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>12.576636</td>\n",
       "      <td>4.785912</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>6.290000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.219057</td>\n",
       "      <td>12.576636</td>\n",
       "      <td>4.785912</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.348082</td>\n",
       "      <td>1.433795</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>12.576636</td>\n",
       "      <td>4.785912</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival  still-alive  age-at-heart-attack  pericardial-effusion  \\\n",
       "33     46.00          0.0                 56.0                   0.0   \n",
       "34     19.50          1.0                 81.0                   0.0   \n",
       "35     20.00          1.0                 59.0                   0.0   \n",
       "36      0.25          1.0                 63.0                   1.0   \n",
       "37      2.00          1.0                 56.0                   1.0   \n",
       "38      7.00          1.0                 61.0                   1.0   \n",
       "\n",
       "    fractional-shortening       epss      lvdd  wall-motion-score  \\\n",
       "33               0.330000  12.576636  3.590000          14.000000   \n",
       "34               0.120000  12.576636  4.785912           9.000000   \n",
       "35               0.030000  21.300000  6.290000          17.000000   \n",
       "36               0.219057  12.576636  4.785912          23.000000   \n",
       "37               0.040000  14.000000  5.000000          15.348082   \n",
       "38               0.270000  12.576636  4.785912           9.000000   \n",
       "\n",
       "    wall-motion-index  alive-at-1  \n",
       "33           1.000000         0.0  \n",
       "34           1.250000         0.0  \n",
       "35           1.310000         0.0  \n",
       "36           2.300000         1.0  \n",
       "37           1.433795         1.0  \n",
       "38           1.500000         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "header = ['survival', 'still-alive', 'age-at-heart-attack', 'pericardial-effusion', 'fractional-shortening', 'epss', 'lvdd', 'wall-motion-score', 'wall-motion-index', 'alive-at-1']\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(data_echo)\n",
    "data_echo = pd.DataFrame(data=imputer.transform(data_echo), columns=header)\n",
    "display(HTML(\"<i>Dataset extract with values imputed:</i>\"))\n",
    "display(data_echo[33:39])\n",
    "X = data_echo.values[:, :9]\n",
    "y = data_echo.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Modelele de clasificare _in a nutshell_</u>\n",
    "Pentru clasificarea datelor din datasetul _Echocardiogram_ vom utiliza următoarele modele de clasificare: kNN, Decision Tree, MLP, Gaussian NB și Random Forest. În paragraful următor vă vom explica modul de funcționare al fiecărui algoritm și evidenția hiperparametrii și formulele care stau la baza acestora.\n",
    "<div style=\"text-align:center\"><img src=\"./Images/xkcd_machine_learning.png\"><br>\"hiperparametrii și formulele care stau la baza acestora\"<br>sursă: <a href=\"https://xkcd.com/1838/\">xkcd 1838: Machine Learning</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1. <i>k</i>-nearest neighbors classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.neighbors.KNeighborsClassifier`<i>(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Într-o problemă de clasificare, algoritmul kNN (_k_-nearest neighbors) identifică cei mai apropiați _k_ vecini ai fiecărui item neclasificat - indiferent de etichetele acestora - vecini localizați în setul de antrenare. Determinarea claselor din care fac parte itemii neclasificați se face prin votare: clasa în care aparțin majoritatea vecinilor se consideră clasa itemului.\n",
    "<div style=\"text-align:center\"><img style=\"width: 500px\" src=\"./Images/knn_example.png\"><br>Exemplu: clasificarea itemului c cu 3NN. În urma votării se determină clasa lui c: <b>o</b>.<br>sursă: <a href=\"http://youtu.be/UqYde-LULfs\">YouTube (<i>How kNN algorithm works</i> de Thales Sehn Körting)</a></div><br>\n",
    "\n",
    "Pentru determinarea distanței dintre itemi se pot utiliza mai multe metrici. Scikit-learn admite orice funcție Python ca și metrică, dar implicit folosește metrica _Minkowski_. Iată câteva exemple de metrici des utilizate în kNN:\n",
    "\n",
    "- _distanța Minkowski_: $d_{st} = \\sqrt[p]{\\sum_{j=1}^n |x_{sj} - y_{tj}|^p}$  (_Obs._: p este un hiperparametru utilizat de Scikit-learn)\n",
    "- _distanța Euclideană_: $d(\\textbf{x},\\textbf{y}) = \\sqrt{\\sum_{i=1}^n (y_i - x_i)^2}$\n",
    "- _distanța Manhattan (City block)_: $d_{st} = \\sum_{j=1}^n |x_{sj} - y_{tj}|$\n",
    "- _distanța Mahalanobis_: $d(\\textbf{x},\\textbf{y}) = \\sqrt{\\sum_{i=1}^n \\frac{(x_i - y_i)^2}{s_i^2}}$, unde $s_i$ este deviația standard a lui $x_i$ și $y_i$ în sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2. Decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.tree.DecisionTreeClassifier`<i>(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un arbore de decizie (_decision tree_) este o structură arborescentă tip flowchart unde un nod intern reprezintă un feature, ramura este un criteriu de decizie, iar fiecare frunză este un rezultat, o clasificare. Algoritmul Decision tree selectează cel mai bun feature folosind o metrică ASM (_Attribute Selection Measure_), convertește un nod feature la un nod tip criteriu de decizie, și partiționează (splits) datasetul în subseturi. Procesul se execută recursiv până arborele conține numai noduri criterii de decizie și noduri frunză rezultat. Cu cât arborele este mai adânc, cu atât sunt mai complexe criteriile de decizie și modelul are o acuratețe mai mare. \n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width: 600px\" src=\"./Images/dt_diagram.png\"><br>Structura unui arbore de decizie.<br>sursă: <a href=\"https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html\">KDnuggets (Decision Tree Algorithm, Explained)</a></div>\n",
    "\n",
    "<br>Pentru măsurarea calității unui split, Scikit-learn utilizează două metrici ASM:\n",
    "\n",
    "- _impuritatea Gini_ (cât de des este etichetat greșit un element ales aleator dacă a fost etichetat folosind distribuția etichetelor dintr-un subset; poate determina overfitting-ul modelului): <br>$Gini(p) = 1 - \\sum_{j=1}^c p_j^2$ <br>\n",
    "- _entropia_ (similar cu Gini impurity, mai intensă d.p.d.v. computațional din cauza funcției logaritmice): <br>$H(p) = - \\sum_{j=1}^c p_j \\log p_j$\n",
    "\n",
    "(unde c este numărul de clase (etichete), iar $p_j$ este subsetul etichetat cu clasă i, unde $j \\in \\{1, 2, ..., c\\}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3. Multilayer perceptron (MLP) classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.neural_network.MLPClassifier`<i>(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Perceptronii_ sunt o clasă de clasificatori utilizați în învățarea supervizată, fiind un model matematic al unui neuron biologic. În particular, _perceptronii multistrat (MLP)_ formează rețele neuronale cu mai multe straturi de perceptroni: un strat de intrare, unul sau mai multe straturi intermediare (ascunse), și un strat de ieșire.\n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width: 500px\" src=\"./Images/mlp_diagram.png\"><br>Un perceptron multistrat ilustrat.<br>sursă: <a href=\"https://github.com/ledell/sldm4-h2o/blob/master/sldm4_h2o_oct2016.pdf\">GitHub (ledell/sldm4-h2o)</a></div>\n",
    "\n",
    "<br>Într-o rețea neuronală, o _funcție de activare_ definește ieșirea unui perceptron după ce este supus unui set de intrare. În forma lui cea mai simplă, funcția poate returna un rezultat binar (funcție liniară, output 0 sau 1): făcând analogie cu neuronul biologic, dacă trece un impuls electric prin axonul acestuia sau nu. În cazul rețelelor neuronale moderne care utilizează mai multe straturi de perceptroni, funcțiile de activare pot fi și non-binare (non-liniare). Scikit-learn admite funcții de activare de ambele tipuri în implementarea MLP classifier:\n",
    "- _funcția identitate_: $f(x) = x$\n",
    "- _sigmoida logistică_: $f(x) = \\frac{1}{1 + \\exp(-x)}$\n",
    "- _tangenta hiperbolică_: $f(x) = \\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
    "- _Rectified Linear Unit (ReLU)_: $f(x) = \\max(0, x) = \\begin{cases} 0 & \\text{dacă } x \\leq 0 \\\\ x & \\text{dacă } x > 0 \\end{cases}$\n",
    "\n",
    "De asemenea, clasificatorul MLP din Scikit-learn utilizează și algoritmi de optimizare a ponderilor (solvers): _LBFGS_ (algoritm Quasi-Newton), _SGD_ (stochastic gradient descent) și _Adam_ (algoritm derivat din SGD, creat de Diederik P. Kingma și Jimmy Lei Ba)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4. Gaussian Naïve Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.naive_bayes.GaussianNB`<i>(priors=None, var_smoothing=1e-09)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmul de clasificare _Gaussian Naïve Bayes_ aparține familiei de clasificatori _Naïve Bayes_, care presupun că prezența unui feature într-o clasă nu este afectată de prezența altor features; pe scurt, proprietățile contribuie independent la probabilitatea apartenenței la o clasă. În particular, algoritmul _Gaussian Naïve Bayes_ urmează funcția de probabilitate (PDF) a unei distribuții normale (Gaussiene):\n",
    "$$\\large P(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y^2}}\\exp\\bigg(-\\frac{(x_i - \\mu_y)^2}{2 \\sigma_y^2}\\bigg),$$\n",
    "unde parametrii $\\sigma_y$ și $\\mu_y$, deviația standard și media, sunt determinați folosind maximum likelihood estimation (MLE), o metodă de estimare a parametrilor unei PDF prin maximizarea unei funcții de likelihood (cât de bine se potrivește un sample cu un model statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5. Random Forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.ensemble.RandomForestClassifier`<i>(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clasificator _Random forest_ se folosește de ipotezele emise de mai mulți arbori de decizie aleatori (_random trees_), obținuți în urma unui _random split_. Un random forest se obține prin construirea unui random tree pentru fiecare set de antrenare. Acești arbori funcționează ca un ansamblu; pentru fiecare dată de intrare se aplică modelele din ansamblu, și rezultatul final se obține agregând rezultatele prin votare. Astfel, un random forest este un _meta-estimator_: se obține o predicție în urma mai multor predicții.\n",
    "<div style=\"text-align:center\"><img style=\"width: 400px\" src=\"./Images/rf_diagram.png\"><br>Un model random forest făcând o predicție; în urma votării se obține rezultatul 1.<br>sursă: <a href=\"https://towardsdatascience.com/understanding-random-forest-58381e0602d2\">Medium (Towards Data Science: Understanding Random Forest)</a></div>\n",
    "\n",
    "<br>La fel ca la _Decision Tree classifier_, pentru măsurarea calității unui split, Scikit-learn utilizează două metrici:\n",
    "\n",
    "- _impuritatea Gini_: $Gini(p) = 1 - \\sum_{j=1}^c p_j^2$ <br>\n",
    "- _entropia_: $H(p) = - \\sum_{j=1}^c p_j \\log p_j$\n",
    "\n",
    "(unde c este numărul de clase (etichete), iar $p_j$ este subsetul etichetat cu clasă i, unde $j \\in \\{1, 2, ..., c\\}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Testarea algoritmilor de clasificare pe setul de date cu Scikit-learn</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a pretty printing function, don't mind me...\n",
    "def print_stats_cv(model_cv_stats):\n",
    "    print(f\"Test accuracy for each fold: {model_cv_stats['test_accuracy']} \\n=> Average test accuracy: {round(model_cv_stats['test_accuracy'].mean() * 100, 3)}%\")\n",
    "    print(f\"Train accuracy for each fold: {model_cv_stats['train_accuracy']} \\n=> Average train accuracy: {round(model_cv_stats['train_accuracy'].mean() * 100, 3)}%\")\n",
    "    print(f\"Test F1 score for each fold: {model_cv_stats['test_f1_macro']} \\n=> Average test F1 score: {round(model_cv_stats['test_f1_macro'].mean() * 100, 3)}%\")\n",
    "    print(f\"Train F1 score for each fold: {model_cv_stats['train_f1_macro']} \\n=> Average train F1 score: {round(model_cv_stats['train_f1_macro'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <i>k</i>-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for 4-nearest neighbors classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.93333333 0.93333333 0.93333333 1.         0.85714286] \n",
      "=> Average test accuracy: 93.143%\n",
      "Train accuracy for each fold: [0.98305085 0.96610169 0.98305085 0.94915254 0.95      ] \n",
      "=> Average train accuracy: 96.627%\n",
      "Test F1 score for each fold: [0.92822967 0.92063492 0.92822967 1.         0.78787879] \n",
      "=> Average test F1 score: 91.299%\n",
      "Train F1 score for each fold: [0.98031365 0.96118421 0.98085037 0.94094094 0.94442729] \n",
      "=> Average train F1 score: 96.154%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# hiperparametri\n",
    "knn_neighbors = 4\n",
    "knn_minkowski_p = 3\n",
    "\n",
    "# scalare date\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# implementare KNN\n",
    "model = KNeighborsClassifier(n_neighbors=knn_neighbors, p=knn_minkowski_p)\n",
    "model_cv_stats = cross_validate(model, X_scaled, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for {knn_neighbors}-nearest neighbors classification:</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Decision Trees classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [1.         1.         0.93333333 0.93333333 1.        ] \n",
      "=> Average test accuracy: 97.333%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [1.         1.         0.92822967 0.92063492 1.        ] \n",
      "=> Average test F1 score: 96.977%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# hiperparametri\n",
    "dt_criterion = 'gini'\n",
    "dt_splitter = 'best'\n",
    "\n",
    "# implementare Decision Tree\n",
    "model = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter, random_state=42)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Decision Trees classification:</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for MLP classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "using hardcoded hyperparameters - Solver: <b>adam</b>, Activation function: <b>relu</b>, Parameter for regularization (α): <b>0.001</b>, Hidden layer sizes: <b>(50, 50)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [1.         0.93333333 1.         0.93333333 1.        ] \n",
      "=> Average test accuracy: 97.333%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [1.         0.92063492 1.         0.92063492 1.        ] \n",
      "=> Average test F1 score: 96.825%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hiperparametri\n",
    "mlp_solver = 'adam'\n",
    "mlp_activation = 'relu'\n",
    "mlp_alpha=1e-3\n",
    "mlp_hidden_layer_sizes = (50,50)\n",
    "\n",
    "# implementare MLP\n",
    "model = MLPClassifier(solver=mlp_solver, activation=mlp_activation, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_layer_sizes, random_state=42, max_iter=1000)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for MLP classification</h4>\"))\n",
    "display(HTML(f\"using hardcoded hyperparameters - Solver: <b>{mlp_solver}</b>, Activation function: <b>{mlp_activation}</b>, Parameter for regularization (α): <b>{mlp_alpha}</b>, Hidden layer sizes: <b>{mlp_hidden_layer_sizes}</b>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Gaussian NB classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.93333333 0.93333333 0.86666667 0.93333333 1.        ] \n",
      "=> Average test accuracy: 93.333%\n",
      "Train accuracy for each fold: [0.94915254 0.94915254 0.96610169 1.         0.93333333] \n",
      "=> Average train accuracy: 95.955%\n",
      "Test F1 score for each fold: [0.92822967 0.92822967 0.86111111 0.92063492 1.        ] \n",
      "=> Average test F1 score: 92.764%\n",
      "Train F1 score for each fold: [0.94393411 0.94393411 0.96217949 1.         0.92822967] \n",
      "=> Average train F1 score: 95.566%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# implementare GNB\n",
    "model = GaussianNB()\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Gaussian NB classification</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Random Forest classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [1.         1.         1.         0.93333333 1.        ] \n",
      "=> Average test accuracy: 98.667%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [1.         1.         1.         0.92063492 1.        ] \n",
      "=> Average test F1 score: 98.413%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# hiperparametri\n",
    "rfc_n_estimators = 150\n",
    "rfc_criterion = 'gini'\n",
    "\n",
    "# implementare Random Forest\n",
    "model = RandomForestClassifier(n_estimators=rfc_n_estimators, criterion=rfc_criterion)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Random Forest classification</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Nested Cross Validation pentru optimizarea hiperparametrilor</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation: split overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train row indices</th>\n",
       "      <th>Test row indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 3, 4, 6, 8, 9, 10, 11, 14, 15, 16, 18, ...</td>\n",
       "      <td>[2, 5, 7, 12, 13, 17, 20, 25, 31, 35, 42, 55, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14,...</td>\n",
       "      <td>[11, 18, 19, 22, 43, 48, 52, 54, 57, 58, 59, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[0, 6, 21, 26, 27, 34, 37, 41, 45, 46, 47, 50,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 2, 3, 5, 6, 7, 9, 11, 12, 13, 14, 16, 17, ...</td>\n",
       "      <td>[1, 4, 8, 10, 15, 28, 29, 30, 39, 44, 49, 53, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>[3, 9, 14, 16, 23, 24, 32, 33, 36, 38, 40, 69,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fold                                  Train row indices  \\\n",
       "0    1  [0, 1, 3, 4, 6, 8, 9, 10, 11, 14, 15, 16, 18, ...   \n",
       "1    2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14,...   \n",
       "2    3  [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "3    4  [0, 2, 3, 5, 6, 7, 9, 11, 12, 13, 14, 16, 17, ...   \n",
       "4    5  [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...   \n",
       "\n",
       "                                    Test row indices  \n",
       "0  [2, 5, 7, 12, 13, 17, 20, 25, 31, 35, 42, 55, ...  \n",
       "1  [11, 18, 19, 22, 43, 48, 52, 54, 57, 58, 59, 6...  \n",
       "2  [0, 6, 21, 26, 27, 34, 37, 41, 45, 46, 47, 50,...  \n",
       "3  [1, 4, 8, 10, 15, 28, 29, 30, 39, 44, 49, 53, ...  \n",
       "4  [3, 9, 14, 16, 23, 24, 32, 33, 36, 38, 40, 69,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CVs configuration\n",
    "inner_cv = KFold(n_splits=4, shuffle=True)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# outer CV folds:\n",
    "print(\"5-fold cross validation: split overview\")\n",
    "splits = outer_cv.split(range(data_echo.index.size))\n",
    "subsets = pd.DataFrame(columns=['Fold', 'Train row indices', 'Test row indices'])\n",
    "for i, split_data in enumerate(splits):\n",
    "    subsets.loc[i]=[i + 1, split_data[0], split_data[1]]\n",
    "display(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <i>k</i>-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'p': 5, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.9285714285714286\n",
      "\n",
      "Average model accuracy: 91.9%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'n_neighbors': np.linspace(start=1, stop=30, num=30, dtype=int),\n",
    "                    'p': np.linspace(start=1, stop=5, num=4, dtype=int)} \n",
    "param_search = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv, random_state=42)\n",
    "    \n",
    "for fold in range(5):\n",
    "    X_train = X_scaled[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X_scaled[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'kNN model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'criterion': 'entropy', 'splitter': 'random'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'random'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 1.0\n",
      "\n",
      "Average model accuracy: 93.29%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'criterion': ['gini', 'entropy'],\n",
    "                    'splitter': ['best', 'random']} \n",
    "param_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Decision Tree model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.06773547094188377, 'activation': 'identity'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.09859719438877755, 'activation': 'identity'}\n",
      "MLP model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.0028056112224448897, 'activation': 'logistic'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.011222444889779559, 'activation': 'relu'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.0935871743486974, 'activation': 'logistic'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.9285714285714286\n",
      "\n",
      "Average model accuracy: 94.46%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'alpha': np.linspace(start=0, stop=1e-1, num=500),\n",
    "                    'activation': ['identity', 'logistic', 'tanh', 'relu']}\n",
    "param_search = RandomizedSearchCV(estimator=MLPClassifier(max_iter=1000), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "     \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'MLP model accuracy with optimal hyperparameters: {accuracy}')\n",
    "     \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.0030260528016032066}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.00022044185971943888}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.006472946244488979}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.008056112418837675}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.0027054115511022047}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.8571428571428571\n",
      "\n",
      "Average model accuracy: 93.54%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'var_smoothing': np.linspace(start=1e-9, stop=1e-2, num=500)} \n",
    "param_search = RandomizedSearchCV(estimator=GaussianNB(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Gaussian Naïve Bayes model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 69, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 236, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 308, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 241, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 47, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "\n",
      "Average model accuracy: 94.17%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'criterion': ['gini', 'entropy'],\n",
    "                   'n_estimators': np.linspace(start=1, stop=500, num=500, dtype=int)} \n",
    "param_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Random Forest Classifier model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
