{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6: modele de clasificare\n",
    "\n",
    "Sîrbu Matei-Dan, _grupa 10LF383_ <br>\n",
    "Tătaru Dragoș-Cătălin, _grupa 10LF383_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataseturile utilizate pentru antrenarea algoritmilor de clasificare:\n",
    "\n",
    "- Wi-Fi localization\n",
    "- Echocardiogram\n",
    "- Seeds\n",
    "- Dermatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Modelele de clasificare in a nutshell</u>\n",
    "Pentru clasificarea datelor din dataseturile enumerate mai sus vom utiliza următoarele modele de clasificare: kNN, Decision Tree, MLP, Gaussian NB și Random Forest. În paragraful următor vă vom explica modul de funcționare al fiecărui algoritm și evidenția hiperparametrii și formulele care stau la baza acestora.\n",
    "<div style=\"text-align:center\"><img src=\"./Images/xkcd_machine_learning.png\"><br>\"hiperparametrii și formulele care stau la baza acestora\"<br>sursă: <a href=\"https://xkcd.com/1838/\">xkcd 1838: Machine Learning</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1. <i>k</i>-nearest neighbors classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.neighbors.KNeighborsClassifier`<i>(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Într-o problemă de clasificare, algoritmul kNN (_k_-nearest neighbors) identifică cei mai apropiați _k_ vecini ai fiecărui item neclasificat - indiferent de etichetele acestora - vecini localizați în setul de antrenare. Determinarea claselor din care fac parte itemii neclasificați se face prin votare: clasa în care aparțin majoritatea vecinilor se consideră clasa itemului.\n",
    "<div style=\"text-align:center\"><img style=\"width: 500px\" src=\"./Images/knn_example.png\"><br>Exemplu: clasificarea itemului c cu 3NN. În urma votării se determină clasa lui c: <b>o</b>.<br>sursă: <a href=\"http://youtu.be/UqYde-LULfs\">YouTube (<i>How kNN algorithm works</i> de Thales Sehn Körting)</a></div><br>\n",
    "\n",
    "Pentru determinarea distanței dintre itemi se pot utiliza mai multe metrici. Scikit-learn admite orice funcție Python ca și metrică, dar implicit folosește metrica _Minkowski_. Iată câteva exemple de metrici des utilizate în kNN:\n",
    "\n",
    "- _distanța Minkowski_: $d_{st} = \\sqrt[p]{\\sum_{j=1}^n |x_{sj} - y_{tj}|^p}$  (_Obs._: p este un hiperparametru utilizat de Scikit-learn)\n",
    "- _distanța Euclideană_: $d(\\textbf{x},\\textbf{y}) = \\sqrt{\\sum_{i=1}^n (y_i - x_i)^2}$\n",
    "- _distanța Manhattan (City block)_: $d_{st} = \\sum_{j=1}^n |x_{sj} - y_{tj}|$\n",
    "- _distanța Mahalanobis_: $d(\\textbf{x},\\textbf{y}) = \\sqrt{\\sum_{i=1}^n \\frac{(x_i - y_i)^2}{s_i^2}}$, unde $s_i$ este deviația standard a lui $x_i$ și $y_i$ în sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2. Decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.tree.DecisionTreeClassifier`<i>(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un arbore de decizie (_decision tree_) este o structură arborescentă tip flowchart unde un nod intern reprezintă un feature, ramura este un criteriu de decizie, iar fiecare frunză este un rezultat, o clasificare. Algoritmul Decision tree selectează cel mai bun feature folosind o metrică ASM (_Attribute Selection Measure_), convertește un nod feature la un nod tip criteriu de decizie, și partiționează (splits) datasetul în subseturi. Procesul se execută recursiv până arborele conține numai noduri criterii de decizie și noduri frunză rezultat. Cu cât arborele este mai adânc, cu atât sunt mai complexe criteriile de decizie și modelul are o acuratețe mai mare. \n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width: 600px\" src=\"./Images/dt_diagram.png\"><br>Structura unui arbore de decizie.<br>sursă: <a href=\"https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html\">KDnuggets (Decision Tree Algorithm, Explained)</a></div>\n",
    "\n",
    "<br>Pentru măsurarea calității unui split, Scikit-learn utilizează două metrici ASM:\n",
    "\n",
    "- _impuritatea Gini_ (cât de des este etichetat greșit un element ales aleator dacă a fost etichetat folosind distribuția etichetelor dintr-un subset; poate determina overfitting-ul modelului): <br>$Gini(p) = 1 - \\sum_{j=1}^c p_j^2$ <br>\n",
    "- _entropia_ (similar cu Gini impurity, mai intensă d.p.d.v. computațional din cauza funcției logaritmice): <br>$H(p) = - \\sum_{j=1}^c p_j \\log p_j$\n",
    "\n",
    "(unde c este numărul de clase (etichete), iar $p_j$ este subsetul etichetat cu clasă i, unde $j \\in \\{1, 2, ..., c\\}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3. Multilayer perceptron (MLP) classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.neural_network.MLPClassifier`<i>(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Perceptronii_ sunt o clasă de clasificatori utilizați în învățarea supervizată, fiind un model matematic al unui neuron biologic. În particular, _perceptronii multistrat (MLP)_ formează rețele neuronale cu mai multe straturi de perceptroni: un strat de intrare, unul sau mai multe straturi intermediare (ascunse), și un strat de ieșire.\n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"width: 500px\" src=\"./Images/mlp_diagram.png\"><br>Un perceptron multistrat ilustrat.<br>sursă: <a href=\"https://github.com/ledell/sldm4-h2o/blob/master/sldm4_h2o_oct2016.pdf\">GitHub (ledell/sldm4-h2o)</a></div>\n",
    "\n",
    "<br>Într-o rețea neuronală, o _funcție de activare_ definește ieșirea unui perceptron după ce este supus unui set de intrare. În forma lui cea mai simplă, funcția poate returna un rezultat binar (funcție liniară, output 0 sau 1): făcând analogie cu neuronul biologic, dacă trece un impuls electric prin axonul acestuia sau nu. În cazul rețelelor neuronale moderne care utilizează mai multe straturi de perceptroni, funcțiile de activare pot fi și non-binare (non-liniare). Scikit-learn admite funcții de activare de ambele tipuri în implementarea MLP classifier:\n",
    "- _funcția identitate_: $f(x) = x$\n",
    "- _sigmoida logistică_: $f(x) = \\frac{1}{1 + \\exp(-x)}$\n",
    "- _tangenta hiperbolică_: $f(x) = \\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
    "- _Rectified Linear Unit (ReLU)_: $f(x) = \\max(0, x) = \\begin{cases} 0 & \\text{dacă } x \\leq 0 \\\\ x & \\text{dacă } x > 0 \\end{cases}$\n",
    "\n",
    "De asemenea, clasificatorul MLP din Scikit-learn utilizează și algoritmi de optimizare a ponderilor (solvers): _LBFGS_ (algoritm Quasi-Newton), _SGD_ (stochastic gradient descent) și _Adam_ (algoritm derivat din SGD, creat de Diederik P. Kingma și Jimmy Lei Ba)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4. Gaussian Naïve Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.naive_bayes.GaussianNB`<i>(priors=None, var_smoothing=1e-09)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmul de clasificare _Gaussian Naïve Bayes_ aparține familiei de clasificatori _Naïve Bayes_, care presupun că prezența unui feature într-o clasă nu este afectată de prezența altor features; pe scurt, proprietățile contribuie independent la probabilitatea apartenenței la o clasă. În particular, algoritmul _Gaussian Naïve Bayes_ urmează funcția de probabilitate (PDF) a unei distribuții normale (Gaussiene):\n",
    "$$\\large P(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y^2}}\\exp\\bigg(-\\frac{(x_i - \\mu_y)^2}{2 \\sigma_y^2}\\bigg),$$\n",
    "unde parametrii $\\sigma_y$ și $\\mu_y$, deviația standard și media, sunt determinați folosind maximum likelihood estimation (MLE), o metodă de estimare a parametrilor unei PDF prin maximizarea unei funcții de likelihood (cât de bine se potrivește un sample cu un model statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5. Random Forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.ensemble.RandomForestClassifier`<i>(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clasificator _Random forest_ se folosește de ipotezele emise de mai mulți arbori de decizie aleatori (_random trees_), obținuți în urma unui _random split_. Un random forest se obține prin construirea unui random tree pentru fiecare set de antrenare. Acești arbori funcționează ca un ansamblu; pentru fiecare dată de intrare se aplică modelele din ansamblu, și rezultatul final se obține agregând rezultatele prin votare. Astfel, un random forest este un _meta-estimator_: se obține o predicție în urma mai multor predicții.\n",
    "<div style=\"text-align:center\"><img style=\"width: 400px\" src=\"./Images/rf_diagram.png\"><br>Un model random forest făcând o predicție; în urma votării se obține rezultatul 1.<br>sursă: <a href=\"https://towardsdatascience.com/understanding-random-forest-58381e0602d2\">Medium (Towards Data Science: Understanding Random Forest)</a></div>\n",
    "\n",
    "<br>La fel ca la _Decision Tree classifier_, pentru măsurarea calității unui split, Scikit-learn utilizează două metrici:\n",
    "\n",
    "- _impuritatea Gini_: $Gini(p) = 1 - \\sum_{j=1}^c p_j^2$ <br>\n",
    "- _entropia_: $H(p) = - \\sum_{j=1}^c p_j \\log p_j$\n",
    "\n",
    "(unde c este numărul de clase (etichete), iar $p_j$ este subsetul etichetat cu clasă i, unde $j \\in \\{1, 2, ..., c\\}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>1. Wi-Fi localization</u>\n",
    "\n",
    "Sîrbu Matei-Dan, _grupa 10LF383_\n",
    "\n",
    "<i>Sursă dataset:</i> http://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization\n",
    "\n",
    "<i>Descriere dataset:</i> [DOI 10.1007/978-981-10-3322-3_27 via ResearchGate](Docs/chp_10.1007_978-981-10-3322-3_27.pdf)\n",
    "\n",
    "<i>Synopsis:</i> Setul de date _Wireless Indoor Localization_ cuprinde 2000 de măsurători ale puterii semnalului (măsurat în dBm) recepționat de la routerele unui birou din Pittsburgh. Acest birou are șapte routere și patru camere; un utilizator înregistrează cu ajutorul unui smartphone o dată pe secundă puterea semnalelor venite de la cele șapte routere, fiecărei înregistrări fiindu-i asociate camera în care se afla utilizatorul la momentul măsurării (1, 2, 3 sau 4).\n",
    "\n",
    "În figura de mai jos este ilustrat un sample din dataset: <br><br>\n",
    "![Sample](./Images/wifi_localization_sample.png)\n",
    "\n",
    "În cele ce urmează, coloana Class (camera) este reprezentată de y, iar coloanele WS1 - WS7 (features: puterea semnalului de la fiecare router), de X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset overview:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS1</th>\n",
       "      <th>WS2</th>\n",
       "      <th>WS3</th>\n",
       "      <th>WS4</th>\n",
       "      <th>WS5</th>\n",
       "      <th>WS6</th>\n",
       "      <th>WS7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64</td>\n",
       "      <td>-56</td>\n",
       "      <td>-61</td>\n",
       "      <td>-66</td>\n",
       "      <td>-71</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-68</td>\n",
       "      <td>-57</td>\n",
       "      <td>-61</td>\n",
       "      <td>-65</td>\n",
       "      <td>-71</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-63</td>\n",
       "      <td>-60</td>\n",
       "      <td>-60</td>\n",
       "      <td>-67</td>\n",
       "      <td>-76</td>\n",
       "      <td>-85</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-61</td>\n",
       "      <td>-60</td>\n",
       "      <td>-68</td>\n",
       "      <td>-62</td>\n",
       "      <td>-77</td>\n",
       "      <td>-90</td>\n",
       "      <td>-80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-63</td>\n",
       "      <td>-65</td>\n",
       "      <td>-60</td>\n",
       "      <td>-63</td>\n",
       "      <td>-77</td>\n",
       "      <td>-81</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-59</td>\n",
       "      <td>-59</td>\n",
       "      <td>-48</td>\n",
       "      <td>-66</td>\n",
       "      <td>-50</td>\n",
       "      <td>-86</td>\n",
       "      <td>-94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-59</td>\n",
       "      <td>-56</td>\n",
       "      <td>-50</td>\n",
       "      <td>-62</td>\n",
       "      <td>-47</td>\n",
       "      <td>-87</td>\n",
       "      <td>-90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-62</td>\n",
       "      <td>-59</td>\n",
       "      <td>-46</td>\n",
       "      <td>-65</td>\n",
       "      <td>-45</td>\n",
       "      <td>-87</td>\n",
       "      <td>-88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-62</td>\n",
       "      <td>-58</td>\n",
       "      <td>-52</td>\n",
       "      <td>-61</td>\n",
       "      <td>-41</td>\n",
       "      <td>-90</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-59</td>\n",
       "      <td>-50</td>\n",
       "      <td>-45</td>\n",
       "      <td>-60</td>\n",
       "      <td>-45</td>\n",
       "      <td>-88</td>\n",
       "      <td>-87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WS1  WS2  WS3  WS4  WS5  WS6  WS7  Class\n",
       "0     -64  -56  -61  -66  -71  -82  -81      1\n",
       "1     -68  -57  -61  -65  -71  -85  -85      1\n",
       "2     -63  -60  -60  -67  -76  -85  -84      1\n",
       "3     -61  -60  -68  -62  -77  -90  -80      1\n",
       "4     -63  -65  -60  -63  -77  -81  -87      1\n",
       "...   ...  ...  ...  ...  ...  ...  ...    ...\n",
       "1995  -59  -59  -48  -66  -50  -86  -94      4\n",
       "1996  -59  -56  -50  -62  -47  -87  -90      4\n",
       "1997  -62  -59  -46  -65  -45  -87  -88      4\n",
       "1998  -62  -58  -52  -61  -41  -90  -85      4\n",
       "1999  -59  -50  -45  -60  -45  -88  -87      4\n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = ['WS1', 'WS2', 'WS3', 'WS4', 'WS5', 'WS6', 'WS7', 'Class']\n",
    "data_wifi = pd.read_csv(\"./Datasets/wifi_localization.txt\", names=header, sep='\\t')\n",
    "display(HTML(\"<i>Dataset overview:</i>\"))\n",
    "display(data_wifi)\n",
    "X = data_wifi.values[:, :7]\n",
    "y = data_wifi.values[:, -1]\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testarea algoritmilor de clasificare pe setul de date cu Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a pretty printing function, don't mind me...\n",
    "def print_stats_cv(model_cv_stats):\n",
    "    print(f\"Test accuracy for each fold: {model_cv_stats['test_accuracy']} \\n=> Average test accuracy: {round(model_cv_stats['test_accuracy'].mean() * 100, 3)}%\")\n",
    "    print(f\"Train accuracy for each fold: {model_cv_stats['train_accuracy']} \\n=> Average train accuracy: {round(model_cv_stats['train_accuracy'].mean() * 100, 3)}%\")\n",
    "    print(f\"Test F1 score for each fold: {model_cv_stats['test_f1_macro']} \\n=> Average test F1 score: {round(model_cv_stats['test_f1_macro'].mean() * 100, 3)}%\")\n",
    "    print(f\"Train F1 score for each fold: {model_cv_stats['train_f1_macro']} \\n=> Average train F1 score: {round(model_cv_stats['train_f1_macro'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <i>k</i>-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for 4-nearest neighbors classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.9675 0.985  0.9675 0.9875 0.9775] \n",
      "=> Average test accuracy: 97.7%\n",
      "Train accuracy for each fold: [0.99     0.99     0.9925   0.99     0.990625] \n",
      "=> Average train accuracy: 99.062%\n",
      "Test F1 score for each fold: [0.96747175 0.98498649 0.96707199 0.98754412 0.97761589] \n",
      "=> Average test F1 score: 97.694%\n",
      "Train F1 score for each fold: [0.98999996 0.99002075 0.99250155 0.9900046  0.99063789] \n",
      "=> Average train F1 score: 99.063%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# hiperparametri\n",
    "knn_neighbors = 4\n",
    "knn_minkowski_p = 3\n",
    "\n",
    "# scalare date\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# implementare KNN\n",
    "model = KNeighborsClassifier(n_neighbors=knn_neighbors, p=knn_minkowski_p)\n",
    "model_cv_stats = cross_validate(model, X_scaled, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for {knn_neighbors}-nearest neighbors classification:</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Decision Trees classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.96   0.9325 0.9275 0.9825 0.9725] \n",
      "=> Average test accuracy: 95.5%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [0.95972496 0.93246313 0.92562893 0.98251804 0.97253289] \n",
      "=> Average test F1 score: 95.457%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# hiperparametri\n",
    "dt_criterion = 'gini'\n",
    "dt_splitter = 'best'\n",
    "\n",
    "# implementare Decision Tree\n",
    "model = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter, random_state=42)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Decision Trees classification:</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for MLP classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "using hardcoded hyperparameters - Solver: <b>adam</b>, Activation function: <b>relu</b>, Parameter for regularization (α): <b>0.001</b>, Hidden layer sizes: <b>(50, 50)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.9725 0.9975 0.95   0.975  0.9775] \n",
      "=> Average test accuracy: 97.45%\n",
      "Train accuracy for each fold: [0.98125  0.971875 0.983125 0.98125  0.981875] \n",
      "=> Average train accuracy: 97.988%\n",
      "Test F1 score for each fold: [0.97244414 0.99749994 0.94983905 0.97514624 0.97746665] \n",
      "=> Average test F1 score: 97.448%\n",
      "Train F1 score for each fold: [0.98124085 0.97171261 0.98314044 0.98122406 0.9819253 ] \n",
      "=> Average train F1 score: 97.985%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hiperparametri\n",
    "mlp_solver = 'adam'\n",
    "mlp_activation = 'relu'\n",
    "mlp_alpha=1e-3\n",
    "mlp_hidden_layer_sizes = (50,50)\n",
    "\n",
    "# implementare MLP\n",
    "model = MLPClassifier(solver=mlp_solver, activation=mlp_activation, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_layer_sizes, random_state=42)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for MLP classification</h4>\"))\n",
    "display(HTML(f\"using hardcoded hyperparameters - Solver: <b>{mlp_solver}</b>, Activation function: <b>{mlp_activation}</b>, Parameter for regularization (α): <b>{mlp_alpha}</b>, Hidden layer sizes: <b>{mlp_hidden_layer_sizes}</b>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Gaussian NB classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.99   0.9725 0.98   0.98   0.985 ] \n",
      "=> Average test accuracy: 98.15%\n",
      "Train accuracy for each fold: [0.98125  0.983125 0.9875   0.985    0.983125] \n",
      "=> Average train accuracy: 98.4%\n",
      "Test F1 score for each fold: [0.99001188 0.97255265 0.9799862  0.98006098 0.9849985 ] \n",
      "=> Average test F1 score: 98.152%\n",
      "Train F1 score for each fold: [0.98127765 0.98313802 0.98751983 0.98501642 0.9831722 ] \n",
      "=> Average train F1 score: 98.402%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# implementare GNB\n",
    "model = GaussianNB()\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Gaussian NB classification</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Random Forest classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.9825 0.9525 0.9775 0.985  0.9875] \n",
      "=> Average test accuracy: 97.7%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [0.98244899 0.95206741 0.97743338 0.9850456  0.98749969] \n",
      "=> Average test F1 score: 97.69%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# hiperparametri\n",
    "rfc_n_estimators = 150\n",
    "rfc_criterion = 'gini'\n",
    "\n",
    "# implementare Random Forest\n",
    "model = RandomForestClassifier(n_estimators=rfc_n_estimators, criterion=rfc_criterion)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Random Forest classification</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Cross Validation pentru optimizarea hiperparametrilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation: split overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train row indices</th>\n",
       "      <th>Test row indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[2, 5, 16, 20, 21, 32, 42, 50, 53, 55, 57, 62,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 16...</td>\n",
       "      <td>[6, 10, 15, 18, 30, 40, 45, 48, 49, 56, 58, 66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 1...</td>\n",
       "      <td>[1, 7, 11, 17, 23, 24, 25, 29, 31, 34, 35, 37,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[0, 3, 19, 38, 41, 44, 54, 64, 72, 79, 83, 90,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 7, 10, 11, 15, 16, 17, 18, ...</td>\n",
       "      <td>[4, 8, 9, 12, 13, 14, 22, 26, 27, 28, 33, 36, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fold                                  Train row indices  \\\n",
       "0    1  [0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "1    2  [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 16...   \n",
       "2    3  [0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 1...   \n",
       "3    4  [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "4    5  [0, 1, 2, 3, 5, 6, 7, 10, 11, 15, 16, 17, 18, ...   \n",
       "\n",
       "                                    Test row indices  \n",
       "0  [2, 5, 16, 20, 21, 32, 42, 50, 53, 55, 57, 62,...  \n",
       "1  [6, 10, 15, 18, 30, 40, 45, 48, 49, 56, 58, 66...  \n",
       "2  [1, 7, 11, 17, 23, 24, 25, 29, 31, 34, 35, 37,...  \n",
       "3  [0, 3, 19, 38, 41, 44, 54, 64, 72, 79, 83, 90,...  \n",
       "4  [4, 8, 9, 12, 13, 14, 22, 26, 27, 28, 33, 36, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CVs configuration\n",
    "inner_cv = KFold(n_splits=4, shuffle=True)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# outer CV folds:\n",
    "print(\"5-fold cross validation: split overview\")\n",
    "splits = outer_cv.split(range(data_wifi.index.size))\n",
    "subsets = pd.DataFrame(columns=['Fold', 'Train row indices', 'Test row indices'])\n",
    "for i, split_data in enumerate(splits):\n",
    "    subsets.loc[i]=[i + 1, split_data[0], split_data[1]]\n",
    "display(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <i>k</i>-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'p': 3, 'n_neighbors': 7}\n",
      "kNN model accuracy with optimal hyperparameters: 0.98\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'p': 3, 'n_neighbors': 3}\n",
      "kNN model accuracy with optimal hyperparameters: 0.985\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'p': 3, 'n_neighbors': 3}\n",
      "kNN model accuracy with optimal hyperparameters: 0.985\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 11}\n",
      "kNN model accuracy with optimal hyperparameters: 0.985\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.985\n",
      "\n",
      "Average model accuracy: 98.4%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'n_neighbors': np.linspace(start=1, stop=30, num=30, dtype=int),\n",
    "                    'p': np.linspace(start=1, stop=5, num=4, dtype=int)} \n",
    "param_search = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv, random_state=42)\n",
    "    \n",
    "for fold in range(5):\n",
    "    X_train = X_scaled[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X_scaled[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'kNN model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'criterion': 'entropy', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.975\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.9525\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'criterion': 'entropy', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.96\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'criterion': 'entropy', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.9825\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'criterion': 'entropy', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.9675\n",
      "\n",
      "Average model accuracy: 96.75%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'criterion': ['gini', 'entropy'],\n",
    "                    'splitter': ['best', 'random']} \n",
    "param_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Decision Tree model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.001002004008016032, 'activation': 'logistic'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.975\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.08857715430861723, 'activation': 'logistic'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.97\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.08336673346693386, 'activation': 'logistic'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.975\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.021042084168336674, 'activation': 'tanh'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.9925\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.06472945891783567, 'activation': 'tanh'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.9675\n",
      "\n",
      "Average model accuracy: 97.6%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'alpha': np.linspace(start=0, stop=1e-1, num=500),\n",
    "                    'activation': ['identity', 'logistic', 'tanh', 'relu']}\n",
    "param_search = RandomizedSearchCV(estimator=MLPClassifier(max_iter=1000), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "     \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'MLP model accuracy with optimal hyperparameters: {accuracy}')\n",
    "     \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.00274549170741483}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.985\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.002404810378757515}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.9825\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.0012024056893787576}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.985\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 2.0041078156312626e-05}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.98\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.002725451629258517}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.9875\n",
      "\n",
      "Average model accuracy: 98.4%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'var_smoothing': np.linspace(start=1e-9, stop=1e-2, num=500)} \n",
    "param_search = RandomizedSearchCV(estimator=GaussianNB(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Gaussian Naïve Bayes model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 404, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.9875\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 386, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.9675\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 246, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.9825\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 52, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.99\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 333, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.985\n",
      "\n",
      "Average model accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'criterion': ['gini', 'entropy'],\n",
    "                   'n_estimators': np.linspace(start=1, stop=500, num=500, dtype=int)} \n",
    "param_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Random Forest Classifier model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>2. Echocardiogram</u>\n",
    "\n",
    "Sîrbu Matei-Dan, _grupa 10LF383_\n",
    "\n",
    "<i>Sursă dataset:</i> http://archive.ics.uci.edu/ml/datasets/Echocardiogram\n",
    "\n",
    "<i>Synopsis:</i> Datasetul _Echocardiogram_ cuprinde 132 de înregistrări de date obținute din ecocardiografiile unor pacienți care au suferit un atac de cord în trecut. Datele sunt utilizate pentru a prezice dacă un pacient va supraviețui cel puțin un an după un atac de cord.\n",
    "\n",
    "În cele ce urmează, atributul **alive-at-1** este reprezentată de y, iar coloanele **survival, still-alive, age-at-heart-attack, pericardial-effusion, fractional-shortening, epss, lvdd, wall-motion-score, wall-motion-index, mult**, de X.\n",
    "\n",
    "_Verbose attribute info:_\n",
    "1. survival -- the number of months patient survived (has survived, if patient is still alive). Because all the patients had their heart attacks at different times, it is possible that some patients have survived less than one year but they are still alive. Check the second variable to confirm this. Such patients cannot be used for the prediction task mentioned above.\n",
    "2. still-alive -- a binary variable. 0=dead at end of survival period, 1 means still alive\n",
    "3. age-at-heart-attack -- age in years when heart attack occurred\n",
    "4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart. 0=no fluid, 1=fluid\n",
    "5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal\n",
    "6. epss -- E-point septal separation, another measure of contractility. Larger numbers are increasingly abnormal.\n",
    "7. lvdd -- left ventricular end-diastolic dimension. This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.\n",
    "8. wall-motion-score -- a measure of how the segments of the left ventricle are moving\n",
    "9. wall-motion-index -- equals wall-motion-score divided by number of segments seen. Usually 12-13 segments are seen in an echocardiogram. Use this variable INSTEAD of the wall motion score.\n",
    "10. mult -- a derivate var which can be ignored\n",
    "11. name -- the name of the patient (I have replaced them with \"name\")\n",
    "12. group -- meaningless, ignore it\n",
    "13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year. 1 means patient was alive at 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset overview:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>mult</th>\n",
       "      <th>name</th>\n",
       "      <th>group</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>9</td>\n",
       "      <td>4.600</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>6</td>\n",
       "      <td>4.100</td>\n",
       "      <td>14</td>\n",
       "      <td>1.700</td>\n",
       "      <td>0.588</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>4</td>\n",
       "      <td>3.420</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253</td>\n",
       "      <td>12.062</td>\n",
       "      <td>4.603</td>\n",
       "      <td>16</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.788</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160</td>\n",
       "      <td>22</td>\n",
       "      <td>5.750</td>\n",
       "      <td>18</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.571</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>12.9</td>\n",
       "      <td>4.72</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.47</td>\n",
       "      <td>11</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.714</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.05</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.857</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>16.1</td>\n",
       "      <td>4.36</td>\n",
       "      <td>15</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.786</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.409</td>\n",
       "      <td>0.786</td>\n",
       "      <td>name</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival still-alive age-at-heart-attack  pericardial-effusion  \\\n",
       "0         11           0                  71                     0   \n",
       "1         19           0                  72                     0   \n",
       "2         16           0                  55                     0   \n",
       "3         57           0                  60                     0   \n",
       "4         19           1                  57                     0   \n",
       "..       ...         ...                 ...                   ...   \n",
       "127      7.5           1                  64                     0   \n",
       "128       41           0                  64                     0   \n",
       "129       36           0                  69                     0   \n",
       "130       22           0                  57                     0   \n",
       "131       20           0                  62                     0   \n",
       "\n",
       "    fractional-shortening    epss   lvdd wall-motion-score wall-motion-index  \\\n",
       "0                   0.260       9  4.600                14                 1   \n",
       "1                   0.380       6  4.100                14             1.700   \n",
       "2                   0.260       4  3.420                14                 1   \n",
       "3                   0.253  12.062  4.603                16             1.450   \n",
       "4                   0.160      22  5.750                18             2.250   \n",
       "..                    ...     ...    ...               ...               ...   \n",
       "127                  0.24    12.9   4.72                12                 1   \n",
       "128                  0.28    5.40   5.47                11              1.10   \n",
       "129                  0.20    7.00   5.05              14.5              1.21   \n",
       "130                  0.14    16.1   4.36                15              1.36   \n",
       "131                  0.15       0   4.51              15.5             1.409   \n",
       "\n",
       "      mult  name group alive-at-1  \n",
       "0        1  name     1          0  \n",
       "1    0.588  name     1          0  \n",
       "2        1  name     1          0  \n",
       "3    0.788  name     1          0  \n",
       "4    0.571  name     1          0  \n",
       "..     ...   ...   ...        ...  \n",
       "127  0.857  name     ?          ?  \n",
       "128  0.714  name     ?          ?  \n",
       "129  0.857  name     ?          ?  \n",
       "130  0.786  name     ?          ?  \n",
       "131  0.786  name     ?          ?  \n",
       "\n",
       "[132 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = ['survival', 'still-alive', 'age-at-heart-attack', 'pericardial-effusion', 'fractional-shortening', 'epss', 'lvdd', 'wall-motion-score', 'wall-motion-index', 'mult', 'name', 'group', 'alive-at-1']\n",
    "data_echo = pd.read_csv(\"./Datasets/echocardiogram.csv\", names=header)\n",
    "display(HTML(\"<i>Dataset overview:</i>\"))\n",
    "display(data_echo)\n",
    "# ignoring irrelevant columns, as per verbose attribute info:\n",
    "del data_echo['mult']\n",
    "del data_echo['name']\n",
    "del data_echo['group']\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum se poate observa în subsolul tabelului, despre unii pacienți nu se știe dacă au supraviețuit la 1 an de la atacul de cord, exact informația pe care vrem să o prezicem după antrenarea modelelor de clasificare. Aceste ecocardiograme se vor elimina din dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Last records in sanitized dataset:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.52</td>\n",
       "      <td>18.16</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5.49</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.29</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>.75</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>40</td>\n",
       "      <td>6.23</td>\n",
       "      <td>14</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.42</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival still-alive age-at-heart-attack  pericardial-effusion  \\\n",
       "104     1.25           1                  63                     0   \n",
       "105       24           0                  59                     0   \n",
       "106       25           0                  57                     0   \n",
       "108      .75           1                  78                     0   \n",
       "109        3           1                  62                     0   \n",
       "\n",
       "    fractional-shortening  epss  lvdd wall-motion-score wall-motion-index  \\\n",
       "104                  0.30   6.9  3.52             18.16              1.51   \n",
       "105                  0.17  14.3  5.49              13.5              1.50   \n",
       "106                 0.228   9.7  4.29                11                 1   \n",
       "108                  0.23    40  6.23                14               1.4   \n",
       "109                  0.26   7.6  4.42                14                 1   \n",
       "\n",
       "    alive-at-1  \n",
       "104          1  \n",
       "105          0  \n",
       "106          0  \n",
       "108          1  \n",
       "109          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_echo = data_echo[(data_echo['alive-at-1'] == '0') | (data_echo['alive-at-1'] == '1')]\n",
    "display(HTML(\"<i>Last records in sanitized dataset:</i>\"))\n",
    "data_echo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De asemenea, unele înregistrări au valori lipsă, valori pe care va trebui să le improvizăm prin _missing value imputation_. Un _imputer_ eficient pe care îl putem utiliza este `KNNImputer` din `sklearn.impute`: acesta aproximează valorile lipsă dintr-o ecocardiogramă analizând _k_ vecini ai acesteia, vecini din punct de vedere al altor parametri existenți. De exemplu, dacă nu cunoaștem variabila **epss**, dar știm valoarea **fractional_shortening**, o putem aproxima pe prima comparând-o pe cea din urmă cu a vecinilor, pentru că amândouă sunt o măsură a contractilității."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset extract with missing values:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.590</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.5</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>21.300</td>\n",
       "      <td>6.290</td>\n",
       "      <td>17</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>2.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survival still-alive age-at-heart-attack  pericardial-effusion  \\\n",
       "43       46           0                  56                     0   \n",
       "46     19.5           1                  81                     0   \n",
       "47       20           1                  59                     0   \n",
       "48     0.25           1                  63                     1   \n",
       "50        2           1                  56                     1   \n",
       "51        7           1                  61                     1   \n",
       "\n",
       "   fractional-shortening    epss   lvdd wall-motion-score wall-motion-index  \\\n",
       "43                 0.330     NaN  3.590                14                 1   \n",
       "46                 0.120     NaN    NaN                 9             1.250   \n",
       "47                 0.030  21.300  6.290                17             1.310   \n",
       "48                   NaN     NaN    NaN                23             2.300   \n",
       "50                 0.040      14      5               NaN               NaN   \n",
       "51                 0.270     NaN    NaN                 9             1.500   \n",
       "\n",
       "   alive-at-1  \n",
       "43          0  \n",
       "46          0  \n",
       "47          0  \n",
       "48          1  \n",
       "50          1  \n",
       "51          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_echo.replace(to_replace='?', value=np.nan, inplace=True)\n",
    "display(HTML(\"<i>Dataset extract with missing values:</i>\"))\n",
    "data_echo[33:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset extract with values imputed using KNNImputer:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>alive-at-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>46.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>9.62</td>\n",
       "      <td>3.590</td>\n",
       "      <td>14.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>19.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>9.18</td>\n",
       "      <td>4.610</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>21.30</td>\n",
       "      <td>6.290</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>16.98</td>\n",
       "      <td>5.124</td>\n",
       "      <td>23.000</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>14.00</td>\n",
       "      <td>5.000</td>\n",
       "      <td>17.534</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>13.00</td>\n",
       "      <td>4.776</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survival  still-alive  age-at-heart-attack  pericardial-effusion  \\\n",
       "33     46.00          0.0                 56.0                   0.0   \n",
       "34     19.50          1.0                 81.0                   0.0   \n",
       "35     20.00          1.0                 59.0                   0.0   \n",
       "36      0.25          1.0                 63.0                   1.0   \n",
       "37      2.00          1.0                 56.0                   1.0   \n",
       "38      7.00          1.0                 61.0                   1.0   \n",
       "\n",
       "    fractional-shortening   epss   lvdd  wall-motion-score  wall-motion-index  \\\n",
       "33                  0.330   9.62  3.590             14.000               1.00   \n",
       "34                  0.120   9.18  4.610              9.000               1.25   \n",
       "35                  0.030  21.30  6.290             17.000               1.31   \n",
       "36                  0.182  16.98  5.124             23.000               2.30   \n",
       "37                  0.040  14.00  5.000             17.534               1.67   \n",
       "38                  0.270  13.00  4.776              9.000               1.50   \n",
       "\n",
       "    alive-at-1  \n",
       "33         0.0  \n",
       "34         0.0  \n",
       "35         0.0  \n",
       "36         1.0  \n",
       "37         1.0  \n",
       "38         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "header = ['survival', 'still-alive', 'age-at-heart-attack', 'pericardial-effusion', 'fractional-shortening', 'epss', 'lvdd', 'wall-motion-score', 'wall-motion-index', 'alive-at-1']\n",
    "imputer = KNNImputer(missing_values=np.nan, n_neighbors=5)\n",
    "imputer.fit(data_echo)\n",
    "data_echo = pd.DataFrame(data=imputer.transform(data_echo), columns=header)\n",
    "display(HTML(\"<i>Dataset extract with values imputed using KNNImputer:</i>\"))\n",
    "display(data_echo[33:39])\n",
    "X = data_echo.values[:, :9]\n",
    "y = data_echo.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testarea algoritmilor de clasificare pe setul de date cu Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <i>k</i>-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for 4-nearest neighbors classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.93333333 0.93333333 0.93333333 0.93333333 0.85714286] \n",
      "=> Average test accuracy: 91.81%\n",
      "Train accuracy for each fold: [0.98305085 0.94915254 0.98305085 0.96610169 0.95      ] \n",
      "=> Average train accuracy: 96.627%\n",
      "Test F1 score for each fold: [0.92822967 0.92063492 0.92822967 0.92063492 0.78787879] \n",
      "=> Average test F1 score: 89.712%\n",
      "Train F1 score for each fold: [0.98031365 0.94094094 0.98085037 0.96118421 0.94442729] \n",
      "=> Average train F1 score: 96.154%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# hiperparametri\n",
    "knn_neighbors = 4\n",
    "knn_minkowski_p = 3\n",
    "\n",
    "# scalare date\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# implementare KNN\n",
    "model = KNeighborsClassifier(n_neighbors=knn_neighbors, p=knn_minkowski_p)\n",
    "model_cv_stats = cross_validate(model, X_scaled, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for {knn_neighbors}-nearest neighbors classification:</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Decision Trees classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [1.         1.         0.93333333 0.93333333 1.        ] \n",
      "=> Average test accuracy: 97.333%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [1.         1.         0.92822967 0.92063492 1.        ] \n",
      "=> Average test F1 score: 96.977%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# hiperparametri\n",
    "dt_criterion = 'gini'\n",
    "dt_splitter = 'best'\n",
    "\n",
    "# implementare Decision Tree\n",
    "model = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter, random_state=42)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Decision Trees classification:</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for MLP classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "using hardcoded hyperparameters - Solver: <b>adam</b>, Activation function: <b>relu</b>, Parameter for regularization (α): <b>0.001</b>, Hidden layer sizes: <b>(50, 50)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [1.         1.         1.         0.93333333 1.        ] \n",
      "=> Average test accuracy: 98.667%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [1.         1.         1.         0.92063492 1.        ] \n",
      "=> Average test F1 score: 98.413%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hiperparametri\n",
    "mlp_solver = 'adam'\n",
    "mlp_activation = 'relu'\n",
    "mlp_alpha=1e-3\n",
    "mlp_hidden_layer_sizes = (50,50)\n",
    "\n",
    "# implementare MLP\n",
    "model = MLPClassifier(solver=mlp_solver, activation=mlp_activation, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_layer_sizes, random_state=42, max_iter=1000)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for MLP classification</h4>\"))\n",
    "display(HTML(f\"using hardcoded hyperparameters - Solver: <b>{mlp_solver}</b>, Activation function: <b>{mlp_activation}</b>, Parameter for regularization (α): <b>{mlp_alpha}</b>, Hidden layer sizes: <b>{mlp_hidden_layer_sizes}</b>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Gaussian NB classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.93333333 0.93333333 0.86666667 0.93333333 1.        ] \n",
      "=> Average test accuracy: 93.333%\n",
      "Train accuracy for each fold: [0.93220339 0.93220339 0.96610169 1.         0.91666667] \n",
      "=> Average train accuracy: 94.944%\n",
      "Test F1 score for each fold: [0.92822967 0.92822967 0.86111111 0.92063492 1.        ] \n",
      "=> Average test F1 score: 92.764%\n",
      "Train F1 score for each fold: [0.92435897 0.92435897 0.96217949 1.         0.90939293] \n",
      "=> Average train F1 score: 94.406%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# implementare GNB\n",
    "model = GaussianNB()\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Gaussian NB classification</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Random Forest classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for each fold: [0.93333333 1.         1.         0.93333333 1.        ] \n",
      "=> Average test accuracy: 97.333%\n",
      "Train accuracy for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score for each fold: [0.92822967 1.         1.         0.92063492 1.        ] \n",
      "=> Average test F1 score: 96.977%\n",
      "Train F1 score for each fold: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# hiperparametri\n",
    "rfc_n_estimators = 150\n",
    "rfc_criterion = 'gini'\n",
    "\n",
    "# implementare Random Forest\n",
    "model = RandomForestClassifier(n_estimators=rfc_n_estimators, criterion=rfc_criterion)\n",
    "model_cv_stats = cross_validate(model, X, y, cv=folds, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Random Forest classification</h4>\"))\n",
    "print_stats_cv(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Cross Validation pentru optimizarea hiperparametrilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation: split overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train row indices</th>\n",
       "      <th>Test row indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[8, 9, 16, 22, 29, 33, 36, 39, 45, 56, 61, 62,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 1...</td>\n",
       "      <td>[0, 2, 10, 23, 25, 28, 43, 49, 51, 53, 54, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 2, 3, 4, 5, 7, 8, 9, 10, 12, 14, 16, 17, 2...</td>\n",
       "      <td>[1, 6, 11, 13, 15, 18, 19, 20, 24, 32, 35, 40,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 1...</td>\n",
       "      <td>[4, 7, 12, 26, 38, 41, 44, 46, 48, 50, 59, 63,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>[3, 5, 14, 17, 21, 27, 30, 31, 34, 37, 42, 47,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fold                                  Train row indices  \\\n",
       "0    1  [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 1...   \n",
       "1    2  [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 1...   \n",
       "2    3  [0, 2, 3, 4, 5, 7, 8, 9, 10, 12, 14, 16, 17, 2...   \n",
       "3    4  [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 1...   \n",
       "4    5  [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 1...   \n",
       "\n",
       "                                    Test row indices  \n",
       "0  [8, 9, 16, 22, 29, 33, 36, 39, 45, 56, 61, 62,...  \n",
       "1  [0, 2, 10, 23, 25, 28, 43, 49, 51, 53, 54, 58,...  \n",
       "2  [1, 6, 11, 13, 15, 18, 19, 20, 24, 32, 35, 40,...  \n",
       "3  [4, 7, 12, 26, 38, 41, 44, 46, 48, 50, 59, 63,...  \n",
       "4  [3, 5, 14, 17, 21, 27, 30, 31, 34, 37, 42, 47,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CVs configuration\n",
    "inner_cv = KFold(n_splits=4, shuffle=True)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# outer CV folds:\n",
    "print(\"5-fold cross validation: split overview\")\n",
    "splits = outer_cv.split(range(data_echo.index.size))\n",
    "subsets = pd.DataFrame(columns=['Fold', 'Train row indices', 'Test row indices'])\n",
    "for i, split_data in enumerate(splits):\n",
    "    subsets.loc[i]=[i + 1, split_data[0], split_data[1]]\n",
    "display(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <i>k</i>-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'p': 3, 'n_neighbors': 7}\n",
      "kNN model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'p': 1, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'p': 5, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'p': 3, 'n_neighbors': 3}\n",
      "kNN model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'p': 5, 'n_neighbors': 12}\n",
      "kNN model accuracy with optimal hyperparameters: 0.9285714285714286\n",
      "\n",
      "Average model accuracy: 93.24%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'n_neighbors': np.linspace(start=1, stop=30, num=30, dtype=int),\n",
    "                    'p': np.linspace(start=1, stop=5, num=4, dtype=int)} \n",
    "param_search = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv, random_state=42)\n",
    "    \n",
    "for fold in range(5):\n",
    "    X_train = X_scaled[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X_scaled[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'kNN model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'criterion': 'entropy', 'splitter': 'random'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'random'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'random'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Decision Tree model accuracy with optimal hyperparameters: 1.0\n",
      "\n",
      "Average model accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'criterion': ['gini', 'entropy'],\n",
    "                    'splitter': ['best', 'random']} \n",
    "param_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Decision Tree model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.03547094188376754, 'activation': 'tanh'}\n",
      "MLP model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.04208416833667335, 'activation': 'tanh'}\n",
      "MLP model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.09458917835671343, 'activation': 'relu'}\n",
      "MLP model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.06653306613226453, 'activation': 'tanh'}\n",
      "MLP model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'alpha': 0.025851703406813628, 'activation': 'relu'}\n",
      "MLP model accuracy with optimal hyperparameters: 1.0\n",
      "\n",
      "Average model accuracy: 98.67%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'alpha': np.linspace(start=0, stop=1e-1, num=500),\n",
    "                    'activation': ['identity', 'logistic', 'tanh', 'relu']}\n",
    "param_search = RandomizedSearchCV(estimator=MLPClassifier(max_iter=1000), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "     \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'MLP model accuracy with optimal hyperparameters: {accuracy}')\n",
    "     \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gaussian Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.0002404819378757515}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.00048096287575150303}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.006332665697394791}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.008056112418837675}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.8666666666666667\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'var_smoothing': 0.007795591402805612}\n",
      "Gaussian Naïve Bayes model accuracy with optimal hyperparameters: 0.9285714285714286\n",
      "\n",
      "Average model accuracy: 93.24%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'var_smoothing': np.linspace(start=1e-9, stop=1e-2, num=500)} \n",
    "param_search = RandomizedSearchCV(estimator=GaussianNB(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Gaussian Naïve Bayes model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 436, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 2, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 53, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 3, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 164, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "Outer fold 4, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 299, 'criterion': 'gini'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 0.9333333333333333\n",
      "Outer fold 5, optimal hyperparameters after inner 4-fold CV: {'n_estimators': 192, 'criterion': 'entropy'}\n",
      "Random Forest Classifier model accuracy with optimal hyperparameters: 1.0\n",
      "\n",
      "Average model accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "outer_cv_acc = []\n",
    "param_candidates = {'criterion': ['gini', 'entropy'],\n",
    "                   'n_estimators': np.linspace(start=1, stop=500, num=500, dtype=int)} \n",
    "param_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_candidates, scoring='accuracy', cv=inner_cv)\n",
    "\n",
    "for fold in range(5):\n",
    "    X_train = X[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    y_train = y[subsets.loc[subsets.index[fold],'Train row indices']]\n",
    "    X_test = X[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    y_test = y[subsets.loc[subsets.index[fold],'Test row indices']]\n",
    "    \n",
    "    param_search.fit(X_train, y_train)\n",
    "    y_estimated = param_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_estimated)\n",
    "    outer_cv_acc.append(accuracy)\n",
    "    \n",
    "    print(f'Outer fold {fold+1}, optimal hyperparameters after inner 4-fold CV: {param_search.best_params_}')\n",
    "    print(f'Random Forest Classifier model accuracy with optimal hyperparameters: {accuracy}')\n",
    "    \n",
    "print(f'\\nAverage model accuracy: {round(np.mean(outer_cv_acc) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>3. Seeds</u>\n",
    "\n",
    "Tătaru Dragoș-Cătălin, _grupa 10LF383_\n",
    "\n",
    "_Sursă dataset:_ http://archive.ics.uci.edu/ml/datasets/Seeds\n",
    "\n",
    "_Articol relevant:_ M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak, 'A Complete Gradient Clustering Algorithm for Features Analysis of X-ray Images', in: Information Technologies in Biomedicine, Ewa Pietka, Jacek Kawa (eds.), Springer-Verlag, Berlin-Heidelberg, 2010, pp. 15-24.\n",
    "\n",
    "_Scurtă descriere:_ Baza de date curentă a fost alcătuită prin scanarea imaginilor unor boabe de grâu din trei specii diferite. Cuprinde 209 intrări și 7 atribute obținute prin cuantificarea parametrilor imaginilor boabelor de grâu.\n",
    "\n",
    "Parametri:\n",
    "- Area\n",
    "- Perimeter\n",
    "- Compactness\n",
    "- Length\n",
    "- Width\n",
    "- Asymmetry\n",
    "- Groove\n",
    "- Class\n",
    "\n",
    "<div style=\"text-align:center\"><img style=\"height: 350px\" src=\"./Images/Seeds_Atributes.png\">  <img style=\"height: 350px\" src=\"./Images/Seeds_X_Ray.png\"><br>(imaginile au fost preluate din articolul sursă citat mai sus.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate,cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3><b>Seeds Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Asymmetry</th>\n",
       "      <th>Groove</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  Perimeter  Compactness  Length  Width  Asymmetry  Groove  Class\n",
       "0    15.26      14.84       0.8710   5.763  3.312      2.221   5.220      1\n",
       "1    14.88      14.57       0.8811   5.554  3.333      1.018   4.956      1\n",
       "2    14.29      14.09       0.9050   5.291  3.337      2.699   4.825      1\n",
       "3    13.84      13.94       0.8955   5.324  3.379      2.259   4.805      1\n",
       "4    16.14      14.99       0.9034   5.658  3.562      1.355   5.175      1\n",
       "..     ...        ...          ...     ...    ...        ...     ...    ...\n",
       "205  12.19      13.20       0.8783   5.137  2.981      3.631   4.870      3\n",
       "206  11.23      12.88       0.8511   5.140  2.795      4.325   5.003      3\n",
       "207  13.20      13.66       0.8883   5.236  3.232      8.315   5.056      3\n",
       "208  11.84      13.21       0.8521   5.175  2.836      3.598   5.044      3\n",
       "209  12.30      13.34       0.8684   5.243  2.974      5.637   5.063      3\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setul de date NU contine valori lipsa\n",
      "Setul de date NU contine valori infinite\n"
     ]
    }
   ],
   "source": [
    "header = ['Area', 'Perimeter', 'Compactness', 'Length', 'Width', 'Asymmetry', 'Groove', 'Class']\n",
    "data_seeds = pd.read_csv(\"./Datasets/seeds_dataset.txt\", names=header,sep='\\t')\n",
    "display(HTML(\"<h3><b>Seeds Dataset\"))\n",
    "X = data_seeds.values[:, :7]\n",
    "y = data_seeds.values[:, -1]\n",
    "display(data_seeds)\n",
    "\n",
    "if np.any(np.isnan(data_seeds))==False:print(\"Setul de date NU contine valori lipsa\")\n",
    "else: print(\"Setul de date contine valori lipsa\")\n",
    "    \n",
    "if np.any(np.isfinite(data_seeds)==True):print(\"Setul de date NU contine valori infinite\")\n",
    "else: print(\"Setul de date contine valori infinite\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The print function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_function(data_set:dict):\n",
    "    df_print = pd.DataFrame({\"Test accuracy for each fold\":data_set['test_accuracy'], \n",
    "                    \"Train accuracy for each fold\": data_set['train_accuracy'], \n",
    "                    \"Average test accuracy %\": round(data_set['test_accuracy'].mean() * 100, 4),\n",
    "                    \"Average train accuracy %\": round(data_set['train_accuracy'].mean() * 100, 4),\n",
    "                    \"Test F1 score for each fold\": data_set['test_f1_macro'],\n",
    "                    \"Train F1 score for each fold\": data_set['train_f1_macro'],\n",
    "                    \"Average test F1 score %\": round(data_set['test_f1_macro'].mean() * 100, 4),\n",
    "                    \"Average train F1 score %\":round(data_set['train_f1_macro'].mean() * 100, 4)\n",
    "                   })\n",
    "    display(HTML(df_print.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executare algoritmi cu hiperparametri hardcodați"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for 5-nearest neighbors classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>95.5952</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>0.940248</td>\n",
       "      <td>92.89</td>\n",
       "      <td>95.5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>95.5952</td>\n",
       "      <td>0.952137</td>\n",
       "      <td>0.946420</td>\n",
       "      <td>92.89</td>\n",
       "      <td>95.5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>95.5952</td>\n",
       "      <td>0.951370</td>\n",
       "      <td>0.946319</td>\n",
       "      <td>92.89</td>\n",
       "      <td>95.5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>95.5952</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.958349</td>\n",
       "      <td>92.89</td>\n",
       "      <td>95.5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>95.5952</td>\n",
       "      <td>0.812454</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>92.89</td>\n",
       "      <td>95.5886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "knn_neighbors = 5\n",
    "knn_minkowski_p = 3\n",
    "\n",
    "# scalare date\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# implementare KNN\n",
    "model = KNeighborsClassifier(n_neighbors=knn_neighbors, p=knn_minkowski_p)\n",
    "model_cv_stats = cross_validate(model, X_scaled, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True) \n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>5-fold cross validation for {knn_neighbors}-nearest neighbors classification:</h4>\"))\n",
    "print_function(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "1    14.334429\n",
      "2    18.334286\n",
      "3    11.873857\n",
      "Name: Area, dtype: float64\n",
      "Class\n",
      "1    14.294286\n",
      "2    16.135714\n",
      "3    13.247857\n",
      "Name: Perimeter, dtype: float64\n",
      "Class\n",
      "1    2.667403\n",
      "2    3.644800\n",
      "3    4.788400\n",
      "Name: Asymmetry, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Decision Trees classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.951370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.8762</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.927742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.8762</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.853236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.8762</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.879979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.8762</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.8762</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "dt_criterion = 'gini'# default value\n",
    "dt_splitter = 'best' # intrebarea care reduce cel mai mult incertitudinea\n",
    "# gini impurity-cantitatea de incertitudine pe un singur nod, cat de amestecate sunt clasificarile din frunze dupa intrebarea din nod\n",
    " \n",
    "# implementare Decision Tree\n",
    "model = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter)\n",
    "model_dc_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "# afisez cateva medii, sa vad daca sunt diferente in functie de clasa\n",
    "\n",
    "print(data_seeds.groupby('Class')['Area'].mean()),\n",
    "print(data_seeds.groupby('Class')['Perimeter'].mean()),\n",
    "print(data_seeds.groupby('Class')['Asymmetry'].mean())\n",
    "\n",
    "display(HTML(f\"<h4>5-fold cross validation for Decision Trees classification:</h4>\"))\n",
    "print_function(model_dc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Random Forest classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.904061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.2476</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.927742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.2476</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.2476</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.2476</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.678255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.2476</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "rfc_n_estimators = 150\n",
    "rfc_criterion = 'gini'\n",
    "\n",
    "# implementare Random Forest\n",
    "model = RandomForestClassifier(n_estimators=rfc_n_estimators, criterion=rfc_criterion)\n",
    "model_rfc_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>5-fold cross validation for Random Forest classification</h4>\"))\n",
    "print_function(model_rfc_stats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.970238</td>\n",
       "      <td>91.4286</td>\n",
       "      <td>97.2619</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>0.970289</td>\n",
       "      <td>91.5605</td>\n",
       "      <td>97.2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>91.4286</td>\n",
       "      <td>97.2619</td>\n",
       "      <td>0.952137</td>\n",
       "      <td>0.976136</td>\n",
       "      <td>91.5605</td>\n",
       "      <td>97.2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>91.4286</td>\n",
       "      <td>97.2619</td>\n",
       "      <td>0.952351</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>91.5605</td>\n",
       "      <td>97.2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>91.4286</td>\n",
       "      <td>97.2619</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>91.5605</td>\n",
       "      <td>97.2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>91.4286</td>\n",
       "      <td>97.2619</td>\n",
       "      <td>0.744997</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>91.5605</td>\n",
       "      <td>97.2596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "mlp_solver = 'adam'\n",
    "mlp_activation = 'logistic'\n",
    "mlp_alpha=1e-3\n",
    "mlp_hidden_layer_sizes = (50,50)\n",
    "max_iter=10000\n",
    "\n",
    "# implementare MLP\n",
    "model = MLPClassifier(solver=mlp_solver, activation=mlp_activation, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_layer_sizes, max_iter=max_iter, random_state=0)\n",
    "model_mpc_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "print_function(model_mpc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Gaussian NB classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>88.5714</td>\n",
       "      <td>91.1905</td>\n",
       "      <td>0.880307</td>\n",
       "      <td>0.904598</td>\n",
       "      <td>88.7466</td>\n",
       "      <td>91.1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>88.5714</td>\n",
       "      <td>91.1905</td>\n",
       "      <td>0.927742</td>\n",
       "      <td>0.898591</td>\n",
       "      <td>88.7466</td>\n",
       "      <td>91.1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>88.5714</td>\n",
       "      <td>91.1905</td>\n",
       "      <td>0.952137</td>\n",
       "      <td>0.910378</td>\n",
       "      <td>88.7466</td>\n",
       "      <td>91.1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>88.5714</td>\n",
       "      <td>91.1905</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>0.903406</td>\n",
       "      <td>88.7466</td>\n",
       "      <td>91.1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>88.5714</td>\n",
       "      <td>91.1905</td>\n",
       "      <td>0.700985</td>\n",
       "      <td>0.940474</td>\n",
       "      <td>88.7466</td>\n",
       "      <td>91.1489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# implementare GNB\n",
    "model = GaussianNB()\n",
    "model_gnb_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>5-fold cross validation for Gaussian NB classification</h4>\"))\n",
    "print_function(model_gnb_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizarea hiperparametrilor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Area', 'Perimeter', 'Compactness', 'Length', 'Width', 'Asymmetry', 'Groove', 'Class']\n",
    "data_seeds = pd.read_csv(\"./Datasets/seeds_dataset.txt\", names=header,sep='\\t')\n",
    "X = data_seeds.values[:, :7]\n",
    "y = data_seeds.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.9047619  0.92857143 0.88095238 0.92857143 1.        ]\n",
      "Media scorurilor: 0.9285714285714286\n",
      "Cel mai bun set de parametri: {'knn__n_neighbors': 9, 'knn__p': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>param_knn__p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 1}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.889695</td>\n",
       "      <td>0.106732</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 2}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.091411</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 3}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904209</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 4}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.076472</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 1}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.120639</td>\n",
       "      <td>36</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.971428</td>\n",
       "      <td>0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 2}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.884888</td>\n",
       "      <td>0.114779</td>\n",
       "      <td>35</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.974593</td>\n",
       "      <td>0.004547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 3}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.889786</td>\n",
       "      <td>0.095789</td>\n",
       "      <td>33</td>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.969816</td>\n",
       "      <td>0.012275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 4}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.084675</td>\n",
       "      <td>31</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.974583</td>\n",
       "      <td>0.011938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 1}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.899673</td>\n",
       "      <td>0.076440</td>\n",
       "      <td>28</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.965059</td>\n",
       "      <td>0.007198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 2}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.889877</td>\n",
       "      <td>0.075312</td>\n",
       "      <td>32</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976145</td>\n",
       "      <td>0.015853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 3}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.913915</td>\n",
       "      <td>0.044440</td>\n",
       "      <td>11</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979320</td>\n",
       "      <td>0.015201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 4}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.057286</td>\n",
       "      <td>30</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>0.974563</td>\n",
       "      <td>0.014270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 1}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.904572</td>\n",
       "      <td>0.070859</td>\n",
       "      <td>20</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.963456</td>\n",
       "      <td>0.014534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 2}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.913824</td>\n",
       "      <td>0.084541</td>\n",
       "      <td>13</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>0.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 3}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913824</td>\n",
       "      <td>0.072835</td>\n",
       "      <td>13</td>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>0.965039</td>\n",
       "      <td>0.017156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 4}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904209</td>\n",
       "      <td>0.089405</td>\n",
       "      <td>25</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.960282</td>\n",
       "      <td>0.016485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 1}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904300</td>\n",
       "      <td>0.078385</td>\n",
       "      <td>21</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.022794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 2}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.913824</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>13</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>0.955495</td>\n",
       "      <td>0.023849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 3}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913824</td>\n",
       "      <td>0.072835</td>\n",
       "      <td>13</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.953922</td>\n",
       "      <td>0.017131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 4}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.918632</td>\n",
       "      <td>0.064567</td>\n",
       "      <td>9</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.952340</td>\n",
       "      <td>0.014671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 1}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904300</td>\n",
       "      <td>0.078385</td>\n",
       "      <td>21</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.015843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 2}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.068171</td>\n",
       "      <td>7</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>0.017510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 3}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.923440</td>\n",
       "      <td>0.056316</td>\n",
       "      <td>5</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.952340</td>\n",
       "      <td>0.014671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 4}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.059480</td>\n",
       "      <td>7</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.947573</td>\n",
       "      <td>0.015296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 1}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.904300</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>21</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.941224</td>\n",
       "      <td>0.023130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 2}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.913915</td>\n",
       "      <td>0.061839</td>\n",
       "      <td>12</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.950738</td>\n",
       "      <td>0.019888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 3}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.923440</td>\n",
       "      <td>0.057875</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.949155</td>\n",
       "      <td>0.017543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 4}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.918632</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>9</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.945971</td>\n",
       "      <td>0.020494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 1}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.909107</td>\n",
       "      <td>0.070105</td>\n",
       "      <td>18</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.942806</td>\n",
       "      <td>0.022543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 2}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.913824</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>13</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.944388</td>\n",
       "      <td>0.019906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 3}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.928066</td>\n",
       "      <td>0.063021</td>\n",
       "      <td>3</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.945971</td>\n",
       "      <td>0.020482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 4}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.928066</td>\n",
       "      <td>0.063021</td>\n",
       "      <td>3</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.941194</td>\n",
       "      <td>0.024918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 1}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.909107</td>\n",
       "      <td>0.060170</td>\n",
       "      <td>18</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.939632</td>\n",
       "      <td>0.024471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 2}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.904300</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>21</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>0.936437</td>\n",
       "      <td>0.027446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 3}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.928157</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.936467</td>\n",
       "      <td>0.020684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 4}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.928157</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.939611</td>\n",
       "      <td>0.024552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('knn', KNeighborsClassifier())])\n",
    "parameter_grid = {'knn__n_neighbors': list(range(1, 10)), 'knn__p': list(range(1, 5))}\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold )\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.83333333 0.85714286 0.9047619  0.88095238 0.95238095]\n",
      "Media scorurilor: 0.8857142857142858\n",
      "Cel mai bun set de parametri: {'dtc__criterion': 'entropy', 'dtc__splitter': 'best'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dtc__criterion</th>\n",
       "      <th>param_dtc__splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>2.257403e-05</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__splitter': 'best'}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.870737</td>\n",
       "      <td>0.105124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1.881091e-06</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__splitter': 'random'}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.860940</td>\n",
       "      <td>0.111945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>{'dtc__criterion': 'entropy', 'dtc__splitter': 'best'}</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.880715</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>2.979636e-06</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>{'dtc__criterion': 'entropy', 'dtc__splitter': 'random'}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875816</td>\n",
       "      <td>0.073019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "parameter_grid = { 'dtc__criterion': ['gini', 'entropy'],'dtc__splitter': ['best', 'random'] }\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold )\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.92857143 0.92857143 0.85714286 0.88095238 0.97619048]\n",
      "Media scorurilor: 0.9142857142857143\n",
      "Cel mai bun set de parametri: {'rfc__criterion': 'gini', 'rfc__n_estimators': 32}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rfc__criterion</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 1}</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.847061</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 7}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.875544</td>\n",
       "      <td>0.128904</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>gini</td>\n",
       "      <td>13</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 13}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.856404</td>\n",
       "      <td>0.150824</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020253</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 19}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.875816</td>\n",
       "      <td>0.109492</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026627</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>gini</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 25}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.861303</td>\n",
       "      <td>0.131747</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033078</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>gini</td>\n",
       "      <td>32</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 32}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.105037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>gini</td>\n",
       "      <td>38</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 38}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.135611</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046144</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>gini</td>\n",
       "      <td>44</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 44}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.861303</td>\n",
       "      <td>0.143825</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 50}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.057427</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>gini</td>\n",
       "      <td>56</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 56}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.880443</td>\n",
       "      <td>0.121421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.065263</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>gini</td>\n",
       "      <td>63</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 63}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.866020</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>gini</td>\n",
       "      <td>69</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 69}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.078157</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>gini</td>\n",
       "      <td>75</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 75}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.125956</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>gini</td>\n",
       "      <td>81</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 81}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.880443</td>\n",
       "      <td>0.109405</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>gini</td>\n",
       "      <td>87</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 87}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.880443</td>\n",
       "      <td>0.121421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.112359</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>gini</td>\n",
       "      <td>94</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 94}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.856495</td>\n",
       "      <td>0.140023</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.116510</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 100}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.870918</td>\n",
       "      <td>0.127412</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.124762</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>gini</td>\n",
       "      <td>106</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 106}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.875635</td>\n",
       "      <td>0.129640</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.131421</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>gini</td>\n",
       "      <td>112</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 112}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.105037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>gini</td>\n",
       "      <td>118</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 118}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.870918</td>\n",
       "      <td>0.127412</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.138303</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>gini</td>\n",
       "      <td>125</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 125}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.875635</td>\n",
       "      <td>0.129640</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.140685</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>gini</td>\n",
       "      <td>131</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 131}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.856495</td>\n",
       "      <td>0.140023</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.140493</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>gini</td>\n",
       "      <td>137</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 137}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.146278</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>gini</td>\n",
       "      <td>143</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 143}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.153933</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 150}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.105037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 1}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.842253</td>\n",
       "      <td>0.088119</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.007673</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 7}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.861393</td>\n",
       "      <td>0.121502</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013845</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 13}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.123479</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.020254</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 19}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.026236</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 25}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.870737</td>\n",
       "      <td>0.148215</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.033546</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>entropy</td>\n",
       "      <td>32</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 32}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.135611</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.039853</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>entropy</td>\n",
       "      <td>38</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 38}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.046485</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>entropy</td>\n",
       "      <td>44</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 44}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.861303</td>\n",
       "      <td>0.131747</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.052363</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 50}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.125956</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.058769</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>entropy</td>\n",
       "      <td>56</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 56}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.866020</td>\n",
       "      <td>0.146113</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.066289</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>entropy</td>\n",
       "      <td>63</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 63}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.880443</td>\n",
       "      <td>0.121421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.073081</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>entropy</td>\n",
       "      <td>69</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 69}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>entropy</td>\n",
       "      <td>75</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 75}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.123393</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.084706</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>entropy</td>\n",
       "      <td>81</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 81}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.123479</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.092922</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>entropy</td>\n",
       "      <td>87</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 87}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.113219</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.098372</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>entropy</td>\n",
       "      <td>94</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 94}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.870918</td>\n",
       "      <td>0.127412</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.105236</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 100}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.111697</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>entropy</td>\n",
       "      <td>106</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 106}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.875635</td>\n",
       "      <td>0.129640</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.117655</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>entropy</td>\n",
       "      <td>112</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 112}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.123055</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>entropy</td>\n",
       "      <td>118</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 118}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.870918</td>\n",
       "      <td>0.127412</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.133070</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>entropy</td>\n",
       "      <td>125</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 125}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.135611</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.138215</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>entropy</td>\n",
       "      <td>131</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 131}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.870827</td>\n",
       "      <td>0.137871</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.148072</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>entropy</td>\n",
       "      <td>137</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 137}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.113219</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.152376</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>entropy</td>\n",
       "      <td>143</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 143}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.875635</td>\n",
       "      <td>0.129640</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 150}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.119231</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('rfc', RandomForestClassifier())])\n",
    "\n",
    "parameter_grid = { 'rfc__criterion': ['gini', 'entropy'],'rfc__n_estimators': np.linspace(start=1, stop=150, num=25, dtype=int)}\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold )\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.92857143 0.88095238 0.97619048 0.95238095 0.78571429]\n",
      "Media scorurilor: 0.9047619047619048\n",
      "Cel mai bun set de parametri: {'gnb__var_smoothing': 0.0028282835454545457}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gnb__var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000963</td>\n",
       "      <td>3.626476e-04</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>9.582039e-05</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>{'gnb__var_smoothing': 1e-09}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000552</td>\n",
       "      <td>2.575990e-05</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>1.331560e-05</td>\n",
       "      <td>0.000101011</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00010101109090909092}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.096003</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>2.678896e-06</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>2.468381e-06</td>\n",
       "      <td>0.000202021</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00020202118181818183}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.096003</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.512596e-06</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>1.741966e-05</td>\n",
       "      <td>0.000303031</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0003030312727272728}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.096003</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>4.289464e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>7.693157e-06</td>\n",
       "      <td>0.000404041</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0004040413636363637}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.096003</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.611531e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.227335e-06</td>\n",
       "      <td>0.000505051</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0005050514545454546}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.875726</td>\n",
       "      <td>0.096003</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000534</td>\n",
       "      <td>2.275930e-05</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>8.535568e-05</td>\n",
       "      <td>0.000606062</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0006060615454545455}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.880533</td>\n",
       "      <td>0.087790</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>1.316710e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.097438e-06</td>\n",
       "      <td>0.000707072</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0007070716363636365}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.617033e-06</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>2.967833e-05</td>\n",
       "      <td>0.000808082</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0008080817272727274}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.887690e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.135621e-06</td>\n",
       "      <td>0.000909092</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0009090918181818183}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>7.725645e-07</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>8.492355e-07</td>\n",
       "      <td>0.0010101</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0010101019090909091}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890149</td>\n",
       "      <td>0.083388</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>4.129531e-07</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>7.907450e-07</td>\n",
       "      <td>0.00111111</td>\n",
       "      <td>{'gnb__var_smoothing': 0.001111112}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.091490</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.917566e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.590450e-06</td>\n",
       "      <td>0.00121212</td>\n",
       "      <td>{'gnb__var_smoothing': 0.001212122090909091}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.091490</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.802979e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>6.165552e-07</td>\n",
       "      <td>0.00131313</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0013131321818181819}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.091490</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>9.291445e-07</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>1.267212e-06</td>\n",
       "      <td>0.00141414</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0014141422727272728}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.091490</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.958809e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.267212e-06</td>\n",
       "      <td>0.00151515</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0015151523636363637}</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.885341</td>\n",
       "      <td>0.091490</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.105501e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>7.027284e-07</td>\n",
       "      <td>0.00161616</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0016161624545454546}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>1.512596e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.265810e-06</td>\n",
       "      <td>0.00171717</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0017171725454545456}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>5.430242e-07</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.174075e-06</td>\n",
       "      <td>0.00181818</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0018181826363636365}</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000523</td>\n",
       "      <td>2.011602e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>3.908538e-07</td>\n",
       "      <td>0.00191919</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0019191927272727274}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.352645e-06</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>1.583499e-05</td>\n",
       "      <td>0.0020202</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0020202028181818183}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.208373e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.208373e-06</td>\n",
       "      <td>0.00212121</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0021212129090909092}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>4.256623e-07</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>2.965294e-06</td>\n",
       "      <td>0.00222222</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002222223}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>1.545531e-05</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.168004e-06</td>\n",
       "      <td>0.00232323</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002323233090909091}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>2.502685e-06</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.548574e-06</td>\n",
       "      <td>0.00242424</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002424243181818182}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>5.430242e-07</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.265810e-06</td>\n",
       "      <td>0.00252525</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002525253272727273}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>8.259062e-07</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>7.794319e-07</td>\n",
       "      <td>0.00262626</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002626263363636364}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>2.128312e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.155777e-06</td>\n",
       "      <td>0.00272727</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0027272734545454548}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>3.066918e-05</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.379947e-06</td>\n",
       "      <td>0.00282828</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0028282835454545457}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>1.743749e-05</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.174075e-06</td>\n",
       "      <td>0.00292929</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0029292936363636366}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>2.141624e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>3.769729e-07</td>\n",
       "      <td>0.0030303</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0030303037272727275}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>6.822063e-07</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>7.202797e-06</td>\n",
       "      <td>0.00313131</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0031313138181818185}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.880146e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>4.129531e-07</td>\n",
       "      <td>0.00323232</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0032323239090909094}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>1.221532e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>7.907450e-07</td>\n",
       "      <td>0.00333333</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0033333340000000003}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.135621e-06</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>1.474537e-06</td>\n",
       "      <td>0.00343434</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0034343440909090912}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.238859e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3.097148e-07</td>\n",
       "      <td>0.00353535</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003535354181818182}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.221532e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.621422e-06</td>\n",
       "      <td>0.00363636</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003636364272727273}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.672120e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>0.00373737</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003737374363636364}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000523</td>\n",
       "      <td>2.387164e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.880146e-06</td>\n",
       "      <td>0.00383838</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003838384454545455}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.602689e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>5.930587e-07</td>\n",
       "      <td>0.00393939</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003939394545454546}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.110312e-06</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>1.016779e-06</td>\n",
       "      <td>0.0040404</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004040404636363637}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.390207e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.180112e-06</td>\n",
       "      <td>0.00414141</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0041414147272727285}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.130919e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>4.129531e-07</td>\n",
       "      <td>0.00424242</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004242424818181819}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.124618e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>0.00434343</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0043434349090909095}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000518</td>\n",
       "      <td>2.775299e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.902686e-06</td>\n",
       "      <td>0.00444445</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004444445000000001}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000670</td>\n",
       "      <td>1.583084e-04</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>2.425944e-04</td>\n",
       "      <td>0.00454546</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004545455090909092}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000584</td>\n",
       "      <td>1.060025e-05</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>6.474722e-06</td>\n",
       "      <td>0.00464647</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004646465181818183}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000542</td>\n",
       "      <td>2.963562e-05</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>4.120488e-06</td>\n",
       "      <td>0.00474748</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004747475272727273}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000556</td>\n",
       "      <td>6.244212e-05</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>6.234939e-05</td>\n",
       "      <td>0.00484849</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0048484853636363645}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>7.917103e-06</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>1.155577e-05</td>\n",
       "      <td>0.0049495</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004949495454545456}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000618</td>\n",
       "      <td>7.848759e-05</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>9.466785e-05</td>\n",
       "      <td>0.00505051</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005050505545454546}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>2.108185e-06</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.124618e-06</td>\n",
       "      <td>0.00515152</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005151515636363637}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000540</td>\n",
       "      <td>2.496994e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>2.141624e-06</td>\n",
       "      <td>0.00525253</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005252525727272728}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000523</td>\n",
       "      <td>2.219823e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.512596e-06</td>\n",
       "      <td>0.00535354</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00535353581818182}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000668</td>\n",
       "      <td>1.462120e-04</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>4.937262e-05</td>\n",
       "      <td>0.00545455</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00545454590909091}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000580</td>\n",
       "      <td>6.429471e-05</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>7.652642e-06</td>\n",
       "      <td>0.00555556</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0055555560000000006}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000547</td>\n",
       "      <td>3.252268e-05</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>4.178706e-06</td>\n",
       "      <td>0.00565657</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005656566090909092}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000534</td>\n",
       "      <td>1.265571e-05</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>3.253780e-06</td>\n",
       "      <td>0.00575758</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005757576181818183}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>2.381114e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>8.820682e-07</td>\n",
       "      <td>0.00585859</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005858586272727274}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>6.873685e-06</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>6.730470e-05</td>\n",
       "      <td>0.0059596</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005959596363636364}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000528</td>\n",
       "      <td>6.848052e-07</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>3.055574e-06</td>\n",
       "      <td>0.00606061</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006060606454545456}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000527</td>\n",
       "      <td>3.411032e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>8.323336e-07</td>\n",
       "      <td>0.00616162</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006161616545454547}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000551</td>\n",
       "      <td>4.679154e-05</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.137184e-06</td>\n",
       "      <td>0.00626263</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0062626266363636374}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>2.246075e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.168008e-06</td>\n",
       "      <td>0.00636364</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006363636727272728}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>1.787146e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>9.610960e-07</td>\n",
       "      <td>0.00646465</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006464646818181819}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>7.420718e-07</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>9.291445e-07</td>\n",
       "      <td>0.00656566</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006565656909090911}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>2.434323e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>8.492355e-07</td>\n",
       "      <td>0.00666667</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006666667000000001}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>1.621422e-06</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.723389e-06</td>\n",
       "      <td>0.00676768</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006767677090909092}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>1.512596e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>2.410122e-06</td>\n",
       "      <td>0.00686869</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006868687181818183}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>2.033558e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.072884e-06</td>\n",
       "      <td>0.0069697</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006969697272727274}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>2.039664e-06</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>2.412648e-05</td>\n",
       "      <td>0.00707071</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007070707363636365}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000528</td>\n",
       "      <td>1.097438e-06</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>3.003388e-06</td>\n",
       "      <td>0.00717172</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007171717454545455}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>2.366237e-06</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>1.592627e-05</td>\n",
       "      <td>0.00727273</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007272727545454547}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000536</td>\n",
       "      <td>1.653962e-05</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>2.174549e-06</td>\n",
       "      <td>0.00737374</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007373737636363638}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000528</td>\n",
       "      <td>2.817856e-06</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>9.610960e-07</td>\n",
       "      <td>0.00747475</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0074747477272727285}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000527</td>\n",
       "      <td>1.611531e-06</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00757576</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007575757818181819}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000530</td>\n",
       "      <td>1.548574e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>2.074207e-06</td>\n",
       "      <td>0.00767677</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00767676790909091}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899492</td>\n",
       "      <td>0.097705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>8.492355e-07</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>3.247419e-05</td>\n",
       "      <td>0.00777778</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007777778000000002}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000542</td>\n",
       "      <td>1.981270e-05</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>2.900487e-06</td>\n",
       "      <td>0.00787879</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00787878809090909}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>1.850626e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>1.276987e-06</td>\n",
       "      <td>0.0079798</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007979798181818182}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>1.788139e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>1.563415e-06</td>\n",
       "      <td>0.00808081</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008080808272727273}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>4.729605e-05</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>6.078505e-07</td>\n",
       "      <td>0.00818182</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008181818363636364}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.000548</td>\n",
       "      <td>3.168114e-05</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>1.002121e-05</td>\n",
       "      <td>0.00828283</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008282828454545456}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>1.174075e-06</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.690083e-06</td>\n",
       "      <td>0.00838384</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008383838545454545}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000557</td>\n",
       "      <td>4.485708e-05</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>5.157273e-05</td>\n",
       "      <td>0.00848485</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008484848636363637}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894684</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>2.081901e-06</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.032383e-07</td>\n",
       "      <td>0.00858586</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008585858727272728}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.889967</td>\n",
       "      <td>0.104140</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>2.451049e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.857333e-06</td>\n",
       "      <td>0.00868687</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008686868818181818}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>9.386549e-07</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.272807e-06</td>\n",
       "      <td>0.00878788</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00878787890909091}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000551</td>\n",
       "      <td>4.584275e-05</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.940587e-06</td>\n",
       "      <td>0.00888889</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008888889}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>2.611745e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>6.822063e-07</td>\n",
       "      <td>0.0089899</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008989899090909092}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>2.026558e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.039242e-06</td>\n",
       "      <td>0.00909091</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009090909181818183}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>2.278177e-05</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>8.513246e-07</td>\n",
       "      <td>0.00919192</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009191919272727273}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>1.632199e-05</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.174075e-06</td>\n",
       "      <td>0.00929293</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009292929363636364}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>2.970680e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>7.609812e-07</td>\n",
       "      <td>0.00939394</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009393939454545456}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000523</td>\n",
       "      <td>1.779176e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.130919e-06</td>\n",
       "      <td>0.00949495</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009494949545454545}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000542</td>\n",
       "      <td>3.024840e-05</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.135621e-06</td>\n",
       "      <td>0.00959596</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009595959636363637}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.184619e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.869725e-06</td>\n",
       "      <td>0.00969697</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009696969727272728}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>1.342098e-06</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>4.129531e-07</td>\n",
       "      <td>0.00979798</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00979797981818182}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.430511e-06</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>0.00989899</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00989898990909091}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000524</td>\n",
       "      <td>9.684608e-07</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>4.539679e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gnb__var_smoothing': 0.01}</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.101125</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('gnb', GaussianNB())])\n",
    "\n",
    "parameter_grid = { 'gnb__var_smoothing': np.linspace(start=1e-9, stop=1e-2, num=100)}\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold )\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.88095238 0.92857143 0.95238095 0.95238095 0.88095238]\n",
      "Media scorurilor: 0.919047619047619\n",
      "Cel mai bun set de parametri: {'mlp__activation': 'identity', 'mlp__alpha': 0.030612244897959186}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_mlp__activation</th>\n",
       "      <th>param_mlp__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351683</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277460</td>\n",
       "      <td>0.166691</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.711720</td>\n",
       "      <td>0.363997</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.154407</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.824020</td>\n",
       "      <td>0.134976</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350732</td>\n",
       "      <td>0.040702</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384516</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.389373</td>\n",
       "      <td>0.026157</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.271325</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.682239</td>\n",
       "      <td>0.340807</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.276706</td>\n",
       "      <td>0.164460</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.754989</td>\n",
       "      <td>0.348501</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.379784</td>\n",
       "      <td>0.058511</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.362626</td>\n",
       "      <td>0.047718</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.368449</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894412</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.378722</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.188614</td>\n",
       "      <td>0.181203</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.245188</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.267392</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.786284</td>\n",
       "      <td>0.194136</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.302922</td>\n",
       "      <td>0.173792</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.783835</td>\n",
       "      <td>0.216191</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.371986</td>\n",
       "      <td>0.052306</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.918451</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.293894</td>\n",
       "      <td>0.167059</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.757710</td>\n",
       "      <td>0.217592</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.171012</td>\n",
       "      <td>0.165220</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.718886</td>\n",
       "      <td>0.225291</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.156742</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.748186</td>\n",
       "      <td>0.225673</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.277531</td>\n",
       "      <td>0.156314</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.776851</td>\n",
       "      <td>0.197250</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.284103</td>\n",
       "      <td>0.162161</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.798258</td>\n",
       "      <td>0.273949</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.250144</td>\n",
       "      <td>0.141058</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.774220</td>\n",
       "      <td>0.259359</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.261858</td>\n",
       "      <td>0.147233</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.819394</td>\n",
       "      <td>0.148672</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.377466</td>\n",
       "      <td>0.037747</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.255139</td>\n",
       "      <td>0.144693</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.819394</td>\n",
       "      <td>0.148672</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.365698</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.373428</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.362646</td>\n",
       "      <td>0.072214</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.262413</td>\n",
       "      <td>0.150023</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.232546</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.351238</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894412</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.336934</td>\n",
       "      <td>0.050184</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.301733</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.790911</td>\n",
       "      <td>0.179331</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.385869</td>\n",
       "      <td>0.035666</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.332639</td>\n",
       "      <td>0.044096</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894412</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.370960</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.385749</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.351861</td>\n",
       "      <td>0.200991</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.795446</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.306659</td>\n",
       "      <td>0.176330</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.807874</td>\n",
       "      <td>0.181596</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.376610</td>\n",
       "      <td>0.032117</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.348942</td>\n",
       "      <td>0.060331</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.268684</td>\n",
       "      <td>0.155004</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.753266</td>\n",
       "      <td>0.248464</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.396451</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.208469</td>\n",
       "      <td>0.211741</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.641963</td>\n",
       "      <td>0.260363</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.430605</td>\n",
       "      <td>0.047253</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.300587</td>\n",
       "      <td>0.168705</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.757983</td>\n",
       "      <td>0.240621</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.245128</td>\n",
       "      <td>0.136411</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.750181</td>\n",
       "      <td>0.268010</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.371199</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.894412</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.263959</td>\n",
       "      <td>0.151842</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.790911</td>\n",
       "      <td>0.179331</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.310790</td>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.367829</td>\n",
       "      <td>0.022417</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.487653</td>\n",
       "      <td>0.039022</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.483045</td>\n",
       "      <td>0.052992</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.456346</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.450599</td>\n",
       "      <td>0.027744</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.467383</td>\n",
       "      <td>0.028560</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.439111</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.464525</td>\n",
       "      <td>0.033810</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.424836</td>\n",
       "      <td>0.044729</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.450619</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.427562</td>\n",
       "      <td>0.029068</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.457203</td>\n",
       "      <td>0.041389</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.418537</td>\n",
       "      <td>0.025772</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.464492</td>\n",
       "      <td>0.060931</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.416121</td>\n",
       "      <td>0.027310</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.457532</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.422272</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.449684</td>\n",
       "      <td>0.051923</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.442092</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.459224</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.427954</td>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.454093</td>\n",
       "      <td>0.046911</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.461232</td>\n",
       "      <td>0.035201</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.442446</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.454583</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.450578</td>\n",
       "      <td>0.028291</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.408854</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.448564</td>\n",
       "      <td>0.042298</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.416899</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.908926</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.423553</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.415690</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.412597</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.447886</td>\n",
       "      <td>0.056683</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.441516</td>\n",
       "      <td>0.045433</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.410822</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.406512</td>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.432258</td>\n",
       "      <td>0.046898</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.402524</td>\n",
       "      <td>0.032459</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.420249</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.429262</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.453512</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.414629</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.424472</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.440434</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.394481</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.423016</td>\n",
       "      <td>0.049221</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.396120</td>\n",
       "      <td>0.039856</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.394439</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.365305</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.401824</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.433351</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.486332</td>\n",
       "      <td>0.080790</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.062947</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.517905</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.536419</td>\n",
       "      <td>0.069850</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.918451</td>\n",
       "      <td>0.078703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.499769</td>\n",
       "      <td>0.073757</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.509246</td>\n",
       "      <td>0.056879</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.486853</td>\n",
       "      <td>0.094242</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.472323</td>\n",
       "      <td>0.088732</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.460528</td>\n",
       "      <td>0.063290</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.497979</td>\n",
       "      <td>0.068180</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.463674</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.055765</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.454734</td>\n",
       "      <td>0.078769</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.465877</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.465199</td>\n",
       "      <td>0.056315</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.468465</td>\n",
       "      <td>0.037330</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.460822</td>\n",
       "      <td>0.060399</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.527248</td>\n",
       "      <td>0.070654</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.463002</td>\n",
       "      <td>0.050465</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.444911</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.471273</td>\n",
       "      <td>0.062230</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.477557</td>\n",
       "      <td>0.074640</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.419927</td>\n",
       "      <td>0.051323</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.454283</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.454105</td>\n",
       "      <td>0.063341</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.442672</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.418816</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.447864</td>\n",
       "      <td>0.050007</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.432983</td>\n",
       "      <td>0.059369</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.466778</td>\n",
       "      <td>0.054806</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.461042</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.446903</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.441366</td>\n",
       "      <td>0.043280</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.452599</td>\n",
       "      <td>0.050464</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.411792</td>\n",
       "      <td>0.055466</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.443999</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.059984</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.474515</td>\n",
       "      <td>0.047108</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.447545</td>\n",
       "      <td>0.030776</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.437934</td>\n",
       "      <td>0.029188</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.913643</td>\n",
       "      <td>0.078861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.456984</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.420715</td>\n",
       "      <td>0.068552</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.427995</td>\n",
       "      <td>0.067898</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.437040</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.427941</td>\n",
       "      <td>0.045817</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.445811</td>\n",
       "      <td>0.041591</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.438206</td>\n",
       "      <td>0.072050</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.421491</td>\n",
       "      <td>0.037046</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.904028</td>\n",
       "      <td>0.094359</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.437821</td>\n",
       "      <td>0.050547</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.443955</td>\n",
       "      <td>0.061676</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.425463</td>\n",
       "      <td>0.238737</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.726234</td>\n",
       "      <td>0.387033</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.455121</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.350011</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.851234</td>\n",
       "      <td>0.171855</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.439499</td>\n",
       "      <td>0.055078</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.447390</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.479742</td>\n",
       "      <td>0.078993</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.480128</td>\n",
       "      <td>0.048797</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.484104</td>\n",
       "      <td>0.040163</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.320753</td>\n",
       "      <td>0.176005</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.748549</td>\n",
       "      <td>0.258839</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.333502</td>\n",
       "      <td>0.194511</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.846426</td>\n",
       "      <td>0.129974</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.452257</td>\n",
       "      <td>0.063284</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.211278</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.776034</td>\n",
       "      <td>0.168733</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.354642</td>\n",
       "      <td>0.201612</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.764695</td>\n",
       "      <td>0.255478</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.396221</td>\n",
       "      <td>0.223525</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.790911</td>\n",
       "      <td>0.179331</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.541863</td>\n",
       "      <td>0.090814</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.378612</td>\n",
       "      <td>0.212123</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.776760</td>\n",
       "      <td>0.201808</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.548628</td>\n",
       "      <td>0.055469</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.563246</td>\n",
       "      <td>0.058151</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.499779</td>\n",
       "      <td>0.107093</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.336894</td>\n",
       "      <td>0.188750</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.762609</td>\n",
       "      <td>0.224711</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.448764</td>\n",
       "      <td>0.254677</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.851234</td>\n",
       "      <td>0.171855</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.537390</td>\n",
       "      <td>0.057154</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.429073</td>\n",
       "      <td>0.241967</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.221281</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.551944</td>\n",
       "      <td>0.102455</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.563157</td>\n",
       "      <td>0.055909</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.391660</td>\n",
       "      <td>0.215717</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.729590</td>\n",
       "      <td>0.279215</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.341045</td>\n",
       "      <td>0.197131</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>0.143356</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.507653</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.449901</td>\n",
       "      <td>0.046101</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.330364</td>\n",
       "      <td>0.188963</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.764695</td>\n",
       "      <td>0.255478</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.339563</td>\n",
       "      <td>0.191278</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.781477</td>\n",
       "      <td>0.194261</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.432343</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.440123</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.415194</td>\n",
       "      <td>0.040613</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.409198</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.328959</td>\n",
       "      <td>0.181894</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>0.150352</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.326490</td>\n",
       "      <td>0.183787</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.812772</td>\n",
       "      <td>0.237807</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.450523</td>\n",
       "      <td>0.067087</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.035246</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.421147</td>\n",
       "      <td>0.050405</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.401602</td>\n",
       "      <td>0.053022</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.407595</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.238228</td>\n",
       "      <td>0.230152</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.618287</td>\n",
       "      <td>0.336415</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.436732</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.235531</td>\n",
       "      <td>0.224347</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.730951</td>\n",
       "      <td>0.256026</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.207565</td>\n",
       "      <td>0.189161</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.719067</td>\n",
       "      <td>0.227113</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.324910</td>\n",
       "      <td>0.193886</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.846335</td>\n",
       "      <td>0.140835</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.411066</td>\n",
       "      <td>0.040338</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.399979</td>\n",
       "      <td>0.037231</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.908835</td>\n",
       "      <td>0.086556</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.303222</td>\n",
       "      <td>0.169174</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.875181</td>\n",
       "      <td>0.142430</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('mlp', MLPClassifier(max_iter= 10000))])\n",
    "\n",
    "parameter_grid = { 'mlp__alpha': np.linspace(start=0, stop=1e-1, num=50),\n",
    "                  'mlp__activation': ['identity', 'logistic', 'tanh', 'relu']\n",
    "                 }\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold )\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>4. Dermatology</u>\n",
    "\n",
    "Tătaru Dragoș-Cătălin, _grupa 10LF383_\n",
    "\n",
    "_Sursă dataset_: http://archive.ics.uci.edu/ml/datasets/Dermatology\n",
    "\n",
    "_Articol relevant_: G. Demiroz, H. A. Govenir, and N. Ilter, \"Learning Differential Diagnosis of Eryhemato-Squamous Diseases using Voting Feature Intervals\", Artificial Intelligence in Medicine\n",
    "\n",
    "_Scurtă descriere_: Baza de date cuprinde informații privitoare la condițiile necesare pentru diagnosticarea diferențiată pentru bolile de piele. Cuprinde 366 intrări și 33 atribute ce pot lua valori între 0 și 3, fiecare dintre acestea indicând severitatea unei condiții medicale. Sunt incluse 6 clase codificate cu cifre între 1 și 6 după cum urmează:\n",
    "\n",
    "_Cuprinde clasele_:\n",
    "- psoriasis\n",
    "- seboreic dermatitis\n",
    "- lichen planus\n",
    "- pityriasis rosea\n",
    "- cronic dermatitis\n",
    "- pityriasis rubra pilaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate,cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "header =['erythema','scaling','definite borders','itching','koebner phenomenon','polygonal papules',\n",
    "'follicular papules','oral mucosal involvement','knee and elbow involvement','scalp involvement','family history','melanin incontinence',\n",
    "'eosinophils in the infiltrate','PNL infiltrate','fibrosis of the papillary dermis','exocytosis','acanthosis','hyperkeratosis',\n",
    "'parakeratosis','clubbing of the rete ridges','elongation of the rete ridges','thinning of the suprapapillary epidermis','spongiform pustule','munro microabcess','focal hypergranulosis',\n",
    "'disappearance of the granular layer','vacuolisation and damage of basal layer','spongiosis','saw-tooth appearance of retes','follicular horn plug','perifollicular parakeratosis','inflammatory monoluclear inflitrate',\n",
    "'band-like infiltrate','Age','Class']\n",
    "\n",
    "print(len(header))\n",
    "# Alcatuim o lista de stringuri ce ar putea reprezenta missing data in data setul nostru\n",
    "missingValues = [\"n/a\", \"na\", \"--\",\" \",\"?\"]\n",
    "data_spam = pd.read_csv(\"./Datasets/dermatology.data\",names=header,sep=',',na_values=missingValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa existenta unor date lipsa, fiecare coloana ar trebui sa aibe 4601 intrari, acest lucru reiese din informatiile despre setul de date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   erythema                                  366 non-null    int64  \n",
      " 1   scaling                                   366 non-null    int64  \n",
      " 2   definite borders                          366 non-null    int64  \n",
      " 3   itching                                   366 non-null    int64  \n",
      " 4   koebner phenomenon                        366 non-null    int64  \n",
      " 5   polygonal papules                         366 non-null    int64  \n",
      " 6   follicular papules                        366 non-null    int64  \n",
      " 7   oral mucosal involvement                  366 non-null    int64  \n",
      " 8   knee and elbow involvement                366 non-null    int64  \n",
      " 9   scalp involvement                         366 non-null    int64  \n",
      " 10  family history                            366 non-null    int64  \n",
      " 11  melanin incontinence                      366 non-null    int64  \n",
      " 12  eosinophils in the infiltrate             366 non-null    int64  \n",
      " 13  PNL infiltrate                            366 non-null    int64  \n",
      " 14  fibrosis of the papillary dermis          366 non-null    int64  \n",
      " 15  exocytosis                                366 non-null    int64  \n",
      " 16  acanthosis                                366 non-null    int64  \n",
      " 17  hyperkeratosis                            366 non-null    int64  \n",
      " 18  parakeratosis                             366 non-null    int64  \n",
      " 19  clubbing of the rete ridges               366 non-null    int64  \n",
      " 20  elongation of the rete ridges             366 non-null    int64  \n",
      " 21  thinning of the suprapapillary epidermis  366 non-null    int64  \n",
      " 22  spongiform pustule                        366 non-null    int64  \n",
      " 23  munro microabcess                         366 non-null    int64  \n",
      " 24  focal hypergranulosis                     366 non-null    int64  \n",
      " 25  disappearance of the granular layer       366 non-null    int64  \n",
      " 26  vacuolisation and damage of basal layer   366 non-null    int64  \n",
      " 27  spongiosis                                366 non-null    int64  \n",
      " 28  saw-tooth appearance of retes             366 non-null    int64  \n",
      " 29  follicular horn plug                      366 non-null    int64  \n",
      " 30  perifollicular parakeratosis              366 non-null    int64  \n",
      " 31  inflammatory monoluclear inflitrate       366 non-null    int64  \n",
      " 32  band-like infiltrate                      366 non-null    int64  \n",
      " 33  Age                                       358 non-null    float64\n",
      " 34  Class                                     366 non-null    int64  \n",
      "dtypes: float64(1), int64(34)\n",
      "memory usage: 100.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erythema                                    0\n",
      "scaling                                     0\n",
      "definite borders                            0\n",
      "itching                                     0\n",
      "koebner phenomenon                          0\n",
      "polygonal papules                           0\n",
      "follicular papules                          0\n",
      "oral mucosal involvement                    0\n",
      "knee and elbow involvement                  0\n",
      "scalp involvement                           0\n",
      "family history                              0\n",
      "melanin incontinence                        0\n",
      "eosinophils in the infiltrate               0\n",
      "PNL infiltrate                              0\n",
      "fibrosis of the papillary dermis            0\n",
      "exocytosis                                  0\n",
      "acanthosis                                  0\n",
      "hyperkeratosis                              0\n",
      "parakeratosis                               0\n",
      "clubbing of the rete ridges                 0\n",
      "elongation of the rete ridges               0\n",
      "thinning of the suprapapillary epidermis    0\n",
      "spongiform pustule                          0\n",
      "munro microabcess                           0\n",
      "focal hypergranulosis                       0\n",
      "disappearance of the granular layer         0\n",
      "vacuolisation and damage of basal layer     0\n",
      "spongiosis                                  0\n",
      "saw-tooth appearance of retes               0\n",
      "follicular horn plug                        0\n",
      "perifollicular parakeratosis                0\n",
      "inflammatory monoluclear inflitrate         0\n",
      "band-like infiltrate                        0\n",
      "Age                                         8\n",
      "Class                                       0\n",
      "dtype: int64\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "display(data_spam.info())\n",
    "# Afisam numarul de missind data in functie de coloana\n",
    "print (data_spam.isnull().sum())\n",
    "# Afisam numarul de missind data in total\n",
    "print (data_spam.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3><b>Dermatology Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>erythema</th>\n",
       "      <th>scaling</th>\n",
       "      <th>definite borders</th>\n",
       "      <th>itching</th>\n",
       "      <th>koebner phenomenon</th>\n",
       "      <th>polygonal papules</th>\n",
       "      <th>follicular papules</th>\n",
       "      <th>oral mucosal involvement</th>\n",
       "      <th>knee and elbow involvement</th>\n",
       "      <th>scalp involvement</th>\n",
       "      <th>family history</th>\n",
       "      <th>melanin incontinence</th>\n",
       "      <th>eosinophils in the infiltrate</th>\n",
       "      <th>PNL infiltrate</th>\n",
       "      <th>fibrosis of the papillary dermis</th>\n",
       "      <th>exocytosis</th>\n",
       "      <th>acanthosis</th>\n",
       "      <th>hyperkeratosis</th>\n",
       "      <th>parakeratosis</th>\n",
       "      <th>clubbing of the rete ridges</th>\n",
       "      <th>elongation of the rete ridges</th>\n",
       "      <th>thinning of the suprapapillary epidermis</th>\n",
       "      <th>spongiform pustule</th>\n",
       "      <th>munro microabcess</th>\n",
       "      <th>focal hypergranulosis</th>\n",
       "      <th>disappearance of the granular layer</th>\n",
       "      <th>vacuolisation and damage of basal layer</th>\n",
       "      <th>spongiosis</th>\n",
       "      <th>saw-tooth appearance of retes</th>\n",
       "      <th>follicular horn plug</th>\n",
       "      <th>perifollicular parakeratosis</th>\n",
       "      <th>inflammatory monoluclear inflitrate</th>\n",
       "      <th>band-like infiltrate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<h3><b>Dermatology Dataset\"))\n",
    "display(HTML(data_spam[5:27].to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inlocuim datele lipsa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>Dataset extract with values imputed:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>erythema</th>\n",
       "      <th>scaling</th>\n",
       "      <th>definite borders</th>\n",
       "      <th>itching</th>\n",
       "      <th>koebner phenomenon</th>\n",
       "      <th>polygonal papules</th>\n",
       "      <th>follicular papules</th>\n",
       "      <th>oral mucosal involvement</th>\n",
       "      <th>knee and elbow involvement</th>\n",
       "      <th>scalp involvement</th>\n",
       "      <th>family history</th>\n",
       "      <th>melanin incontinence</th>\n",
       "      <th>eosinophils in the infiltrate</th>\n",
       "      <th>PNL infiltrate</th>\n",
       "      <th>fibrosis of the papillary dermis</th>\n",
       "      <th>exocytosis</th>\n",
       "      <th>acanthosis</th>\n",
       "      <th>hyperkeratosis</th>\n",
       "      <th>parakeratosis</th>\n",
       "      <th>clubbing of the rete ridges</th>\n",
       "      <th>elongation of the rete ridges</th>\n",
       "      <th>thinning of the suprapapillary epidermis</th>\n",
       "      <th>spongiform pustule</th>\n",
       "      <th>munro microabcess</th>\n",
       "      <th>focal hypergranulosis</th>\n",
       "      <th>disappearance of the granular layer</th>\n",
       "      <th>vacuolisation and damage of basal layer</th>\n",
       "      <th>spongiosis</th>\n",
       "      <th>saw-tooth appearance of retes</th>\n",
       "      <th>follicular horn plug</th>\n",
       "      <th>perifollicular parakeratosis</th>\n",
       "      <th>inflammatory monoluclear inflitrate</th>\n",
       "      <th>band-like infiltrate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2.,  0., ...,  1.,  0., 55.],\n",
       "       [ 3.,  3.,  3., ...,  1.,  0.,  8.],\n",
       "       [ 2.,  1.,  2., ...,  2.,  3., 26.],\n",
       "       ...,\n",
       "       [ 3.,  2.,  2., ...,  2.,  3., 28.],\n",
       "       [ 2.,  1.,  3., ...,  2.,  3., 50.],\n",
       "       [ 3.,  2.,  2., ...,  3.,  0., 35.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "print(imputer)\n",
    "imputer.fit(data_spam)\n",
    "data_spam = pd.DataFrame(data=imputer.transform(data_spam), columns=header)\n",
    "\n",
    "display(HTML(\"<i>Dataset extract with values imputed:</i>\"))\n",
    "display(HTML(data_spam[5:20].to_html()))\n",
    "\n",
    "X = data_spam.values[:, :34]\n",
    "y = data_spam.values[:, -1]\n",
    "\n",
    "display(X)\n",
    "display(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The print Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_function(data_set:dict):\n",
    "    df_print = pd.DataFrame({\"Test accuracy for each fold\":data_set['test_accuracy'], \n",
    "                    \"Train accuracy for each fold\": data_set['train_accuracy'], \n",
    "                    \"Average test accuracy %\": round(data_set['test_accuracy'].mean() * 100, 4),\n",
    "                    \"Average train accuracy %\": round(data_set['train_accuracy'].mean() * 100, 4),\n",
    "                    \"Test F1 score for each fold\": data_set['test_f1_macro'],\n",
    "                    \"Train F1 score for each fold\": data_set['train_f1_macro'],\n",
    "                    \"Average test F1 score %\": round(data_set['test_f1_macro'].mean() * 100, 4),\n",
    "                    \"Average train F1 score %\":round(data_set['train_f1_macro'].mean() * 100, 4)\n",
    "                   })\n",
    "    display(HTML(df_print.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executare algoritmi cu hiperparametri hardcodați:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for 5-nearest neighbors classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.982877</td>\n",
       "      <td>95.0833</td>\n",
       "      <td>97.5415</td>\n",
       "      <td>0.946673</td>\n",
       "      <td>0.981964</td>\n",
       "      <td>94.7936</td>\n",
       "      <td>97.3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.976109</td>\n",
       "      <td>95.0833</td>\n",
       "      <td>97.5415</td>\n",
       "      <td>0.942044</td>\n",
       "      <td>0.973730</td>\n",
       "      <td>94.7936</td>\n",
       "      <td>97.3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>95.0833</td>\n",
       "      <td>97.5415</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.970766</td>\n",
       "      <td>94.7936</td>\n",
       "      <td>97.3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.976109</td>\n",
       "      <td>95.0833</td>\n",
       "      <td>97.5415</td>\n",
       "      <td>0.988188</td>\n",
       "      <td>0.974982</td>\n",
       "      <td>94.7936</td>\n",
       "      <td>97.3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.969283</td>\n",
       "      <td>95.0833</td>\n",
       "      <td>97.5415</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>94.7936</td>\n",
       "      <td>97.3208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "knn_neighbors = 5\n",
    "knn_minkowski_p = 3\n",
    "\n",
    "# scalare date\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# implementare KNN\n",
    "model = KNeighborsClassifier(n_neighbors=knn_neighbors, p=knn_minkowski_p)\n",
    "model_cv_stats = cross_validate(model, X_scaled, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True) \n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>5-fold cross validation for {knn_neighbors}-nearest neighbors classification:</h4>\"))\n",
    "print_function(model_cv_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Decision Trees classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.625</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.905717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.2922</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.625</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.986581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.2922</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.625</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.883445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.2922</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.625</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.899474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.2922</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.945205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.625</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.2922</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "dt_criterion = 'gini'#default value\n",
    "dt_splitter = 'best' #intrebarea care reduce cel mai mult incertitudinea\n",
    "#gini imputity-cantitatea de incertitudine pe un singur nod, cat de amestecate sunt clasificarile din frunze dupa intrebarea din nod\n",
    " \n",
    "# implementare Decision Tree\n",
    "model = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter)\n",
    "model_dc_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>5-fold cross validation for Decision Trees classification:</h4>\"))\n",
    "print_function(model_dc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Random Forest classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.5417</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.974704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.3621</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.5417</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.3621</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.5417</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.3621</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.5417</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.984561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.3621</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.945205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.5417</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.3621</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "rfc_n_estimators = 150\n",
    "rfc_criterion = 'gini'\n",
    "\n",
    "# implementare Random Forest\n",
    "model = RandomForestClassifier(n_estimators=rfc_n_estimators, criterion=rfc_criterion)\n",
    "model_rfc_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>5-fold cross validation for Random Forest classification</h4>\"))\n",
    "print_function(model_rfc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.9974</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.956190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.6856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.9974</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.6856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.9974</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.6856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.9974</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.984561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.6856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.931507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.9974</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.924086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.6856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hiperparametri\n",
    "mlp_solver = 'adam'\n",
    "mlp_activation = 'logistic'\n",
    "mlp_alpha=1e-3\n",
    "mlp_hidden_layer_sizes = (50,50)\n",
    "max_iter=1000\n",
    "\n",
    "# implementare MLP\n",
    "model = MLPClassifier(solver=mlp_solver, activation=mlp_activation, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_layer_sizes, max_iter=max_iter, random_state=0)\n",
    "model_mpc_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "print_function(model_mpc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Gaussian NB classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test accuracy for each fold</th>\n",
       "      <th>Train accuracy for each fold</th>\n",
       "      <th>Average test accuracy %</th>\n",
       "      <th>Average train accuracy %</th>\n",
       "      <th>Test F1 score for each fold</th>\n",
       "      <th>Train F1 score for each fold</th>\n",
       "      <th>Average test F1 score %</th>\n",
       "      <th>Average train F1 score %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.900685</td>\n",
       "      <td>87.4232</td>\n",
       "      <td>89.9591</td>\n",
       "      <td>0.892797</td>\n",
       "      <td>0.882689</td>\n",
       "      <td>83.8773</td>\n",
       "      <td>88.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.904437</td>\n",
       "      <td>87.4232</td>\n",
       "      <td>89.9591</td>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.888485</td>\n",
       "      <td>83.8773</td>\n",
       "      <td>88.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.901024</td>\n",
       "      <td>87.4232</td>\n",
       "      <td>89.9591</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.884780</td>\n",
       "      <td>83.8773</td>\n",
       "      <td>88.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>87.4232</td>\n",
       "      <td>89.9591</td>\n",
       "      <td>0.848276</td>\n",
       "      <td>0.867591</td>\n",
       "      <td>83.8773</td>\n",
       "      <td>88.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.901024</td>\n",
       "      <td>87.4232</td>\n",
       "      <td>89.9591</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.883966</td>\n",
       "      <td>83.8773</td>\n",
       "      <td>88.1502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# implementare GNB\n",
    "model = GaussianNB()\n",
    "model_gnb_stats = cross_validate(model, X, y, cv=5, scoring=('accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>5-fold cross validation for Gaussian NB classification</h4>\"))\n",
    "print_function(model_gnb_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizarea hiperparametrilor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.98648649 0.95890411 0.95890411 1.         0.95890411]\n",
      "Media scorurilor: 0.972639763050722\n",
      "Cel mai bun set de parametri: {'knn__n_neighbors': 6, 'knn__p': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>param_knn__p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956193</td>\n",
       "      <td>0.017508</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 2}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.950699</td>\n",
       "      <td>0.022792</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 3}</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.937082</td>\n",
       "      <td>0.018140</td>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'knn__p': 4}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.931617</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 1}</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.953506</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>14</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.984506</td>\n",
       "      <td>0.008324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 2}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.953446</td>\n",
       "      <td>0.022550</td>\n",
       "      <td>16</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.983600</td>\n",
       "      <td>0.006584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 3}</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.937052</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>31</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.983600</td>\n",
       "      <td>0.006584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 2, 'knn__p': 4}</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.934365</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>33</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.981782</td>\n",
       "      <td>0.004481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.961718</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.982691</td>\n",
       "      <td>0.005979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 2}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956163</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>13</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.981778</td>\n",
       "      <td>0.006828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 3}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.945234</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>28</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.983600</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.014792</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__p': 4}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.942517</td>\n",
       "      <td>0.021285</td>\n",
       "      <td>29</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.985421</td>\n",
       "      <td>0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.948011</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>25</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.984512</td>\n",
       "      <td>0.006996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 2}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.953446</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>16</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.985421</td>\n",
       "      <td>0.004481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.014773</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 3}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950729</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>21</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.979957</td>\n",
       "      <td>0.004106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'knn__p': 4}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>18</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.978139</td>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>6</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>0.003985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 2}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.958970</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>8</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.015349</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 3}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956223</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>10</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.976327</td>\n",
       "      <td>0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__p': 4}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.950699</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>24</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.967212</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.979960</td>\n",
       "      <td>0.003180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 2}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>7</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.979058</td>\n",
       "      <td>0.004705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.014807</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 3}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.953506</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>14</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.014678</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'knn__p': 4}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.948011</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>26</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 1}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.967152</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>3</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.979051</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 2}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.950729</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>21</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.974496</td>\n",
       "      <td>0.004486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 3}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>18</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.972678</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__p': 4}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.931558</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>35</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 1}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.967212</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>2</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 2}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956193</td>\n",
       "      <td>0.020671</td>\n",
       "      <td>11</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.973580</td>\n",
       "      <td>0.005427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 3}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>18</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.971768</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'knn__p': 4}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.937052</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>32</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.965392</td>\n",
       "      <td>0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 1}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964465</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.975405</td>\n",
       "      <td>0.003062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 2}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.958911</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>9</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.967203</td>\n",
       "      <td>0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 3}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>27</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.967206</td>\n",
       "      <td>0.004508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>{'knn__n_neighbors': 9, 'knn__p': 4}</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.926123</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>36</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.965388</td>\n",
       "      <td>0.001885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('knn', KNeighborsClassifier())])\n",
    "parameter_grid = {'knn__n_neighbors': list(range(1, 10)), 'knn__p': list(range(1, 5))}\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4, return_train_score=True)\n",
    "\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold)\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.97297297 0.93150685 0.94520548 0.95890411 0.93150685]\n",
      "Media scorurilor: 0.9480192521288411\n",
      "Cel mai bun set de parametrii: {'dtc__criterion': 'entropy', 'dtc__splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dtc__criterion</th>\n",
       "      <th>param_dtc__splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>6.813087e-05</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__splitter': 'best'}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.939949</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>5.556675e-06</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>{'dtc__criterion': 'gini', 'dtc__splitter': 'random'}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.923614</td>\n",
       "      <td>0.030619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>4.595990e-05</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>{'dtc__criterion': 'entropy', 'dtc__splitter': 'best'}</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.918180</td>\n",
       "      <td>0.046895</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>8.658075e-07</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>{'dtc__criterion': 'entropy', 'dtc__splitter': 'random'}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.948190</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "parameter_grid = { 'dtc__criterion': ['gini', 'entropy'],'dtc__splitter': ['best', 'random'] }\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold)\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametrii:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.98648649 0.98630137 0.95890411 0.94520548 0.98630137]\n",
      "Media scorurilor: 0.9726397630507219\n",
      "Cel mai bun set de parametri: {'rfc__criterion': 'gini', 'rfc__n_estimators': 69}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rfc__criterion</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 1}</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.866012</td>\n",
       "      <td>0.030863</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 7}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.950729</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>gini</td>\n",
       "      <td>13</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 13}</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.961747</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 19}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028297</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>gini</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 25}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>gini</td>\n",
       "      <td>32</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 32}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.041022</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>gini</td>\n",
       "      <td>38</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 38}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.047801</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>gini</td>\n",
       "      <td>44</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 44}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.023813</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 50}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061237</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>gini</td>\n",
       "      <td>56</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 56}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.067394</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>gini</td>\n",
       "      <td>63</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 63}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.074570</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>gini</td>\n",
       "      <td>69</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 69}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.980829</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.079382</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>gini</td>\n",
       "      <td>75</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 75}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.086541</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>gini</td>\n",
       "      <td>81</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 81}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.978052</td>\n",
       "      <td>0.017394</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.093252</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>gini</td>\n",
       "      <td>87</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 87}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.100054</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>gini</td>\n",
       "      <td>94</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 94}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.106366</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 100}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.112122</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>gini</td>\n",
       "      <td>106</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 106}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.119777</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>gini</td>\n",
       "      <td>112</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 112}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.127990</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>gini</td>\n",
       "      <td>118</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 118}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.133450</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>gini</td>\n",
       "      <td>125</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 125}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.140445</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>gini</td>\n",
       "      <td>131</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 131}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.145426</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>gini</td>\n",
       "      <td>137</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 137}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.152084</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>gini</td>\n",
       "      <td>143</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 143}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.159127</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>{'rfc__criterion': 'gini', 'rfc__n_estimators': 150}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.975364</td>\n",
       "      <td>0.014224</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 1}</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.882645</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 7}</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.934514</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 13}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956163</td>\n",
       "      <td>0.024653</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 19}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956163</td>\n",
       "      <td>0.031082</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.027391</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 25}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.034681</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>entropy</td>\n",
       "      <td>32</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 32}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964345</td>\n",
       "      <td>0.028447</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.041642</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>entropy</td>\n",
       "      <td>38</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 38}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956223</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>entropy</td>\n",
       "      <td>44</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 44}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.055081</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>entropy</td>\n",
       "      <td>56</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 56}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.068898</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>entropy</td>\n",
       "      <td>63</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 63}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.075024</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>entropy</td>\n",
       "      <td>69</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 69}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969810</td>\n",
       "      <td>0.025052</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.081934</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>entropy</td>\n",
       "      <td>75</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 75}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.087801</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>entropy</td>\n",
       "      <td>81</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 81}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.095682</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>entropy</td>\n",
       "      <td>87</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 87}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.100633</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>entropy</td>\n",
       "      <td>94</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 94}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.972617</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.108182</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 100}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.114108</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>entropy</td>\n",
       "      <td>106</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 106}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.120974</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>entropy</td>\n",
       "      <td>112</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 112}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.021056</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.136287</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>entropy</td>\n",
       "      <td>118</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 118}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.135403</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>entropy</td>\n",
       "      <td>125</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 125}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.021056</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.144191</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.009755</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>entropy</td>\n",
       "      <td>131</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 131}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.149123</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>entropy</td>\n",
       "      <td>137</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 137}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.154789</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>entropy</td>\n",
       "      <td>143</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 143}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972587</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>{'rfc__criterion': 'entropy', 'rfc__n_estimators': 150}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('rfc', RandomForestClassifier())])\n",
    "\n",
    "parameter_grid = { 'rfc__criterion': ['gini', 'entropy'],'rfc__n_estimators': np.linspace(start=1, stop=150, num=25, dtype=int)}\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold)\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.95945946 0.93150685 0.98630137 0.94520548 1.        ]\n",
      "Media scorurilor: 0.9644946316179193\n",
      "Cel mai bun set de parametri: {'gnb__var_smoothing': 0.0004040413636363637}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gnb__var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001019</td>\n",
       "      <td>4.165698e-04</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>2.599635e-04</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>{'gnb__var_smoothing': 1e-09}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.885213</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.222157e-05</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>1.361532e-05</td>\n",
       "      <td>0.000101011</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00010101109090909092}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956193</td>\n",
       "      <td>0.020671</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000773</td>\n",
       "      <td>4.195604e-05</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>1.819651e-06</td>\n",
       "      <td>0.000202021</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00020202118181818183}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000751</td>\n",
       "      <td>3.456556e-06</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>2.440153e-06</td>\n",
       "      <td>0.000303031</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0003030312727272728}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000772</td>\n",
       "      <td>4.034032e-05</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>1.610991e-05</td>\n",
       "      <td>0.000404041</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0004040413636363637}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.967093</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000749</td>\n",
       "      <td>4.904995e-06</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>1.572479e-06</td>\n",
       "      <td>0.000505051</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0005050514545454546}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.784161e-06</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>1.819651e-06</td>\n",
       "      <td>0.000606062</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0006060615454545455}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000793</td>\n",
       "      <td>7.751886e-05</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>4.975471e-06</td>\n",
       "      <td>0.000707072</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0007070716363636365}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>6.358170e-06</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>2.827925e-06</td>\n",
       "      <td>0.000808082</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0008080817272727274}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000761</td>\n",
       "      <td>2.766394e-05</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1.344804e-04</td>\n",
       "      <td>0.000909092</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0009090918181818183}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000750</td>\n",
       "      <td>7.618910e-06</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>3.041589e-06</td>\n",
       "      <td>0.0010101</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0010101019090909091}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>6.380482e-06</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>8.917859e-05</td>\n",
       "      <td>0.00111111</td>\n",
       "      <td>{'gnb__var_smoothing': 0.001111112}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000960</td>\n",
       "      <td>6.271573e-05</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>5.464169e-05</td>\n",
       "      <td>0.00121212</td>\n",
       "      <td>{'gnb__var_smoothing': 0.001212122090909091}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000902</td>\n",
       "      <td>9.847582e-06</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>4.290553e-05</td>\n",
       "      <td>0.00131313</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0013131321818181819}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000968</td>\n",
       "      <td>5.830721e-05</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>2.924882e-06</td>\n",
       "      <td>0.00141414</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0014141422727272728}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000870</td>\n",
       "      <td>4.904329e-05</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>4.522355e-05</td>\n",
       "      <td>0.00151515</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0015151523636363637}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>5.731039e-05</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>6.116688e-05</td>\n",
       "      <td>0.00161616</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0016161624545454546}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000917</td>\n",
       "      <td>2.431110e-05</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>5.601349e-05</td>\n",
       "      <td>0.00171717</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0017171725454545456}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000802</td>\n",
       "      <td>4.309457e-05</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>4.700460e-06</td>\n",
       "      <td>0.00181818</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0018181826363636365}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000764</td>\n",
       "      <td>9.686809e-06</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>5.208164e-06</td>\n",
       "      <td>0.00191919</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0019191927272727274}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000750</td>\n",
       "      <td>2.573375e-06</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>1.238859e-06</td>\n",
       "      <td>0.0020202</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0020202028181818183}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>1.030661e-06</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>2.756675e-06</td>\n",
       "      <td>0.00212121</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0021212129090909092}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000750</td>\n",
       "      <td>7.907450e-07</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>3.324572e-05</td>\n",
       "      <td>0.00222222</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002222223}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>8.758993e-05</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>1.051359e-04</td>\n",
       "      <td>0.00232323</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002323233090909091}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000883</td>\n",
       "      <td>2.163379e-04</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>4.847555e-05</td>\n",
       "      <td>0.00242424</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002424243181818182}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000752</td>\n",
       "      <td>5.965231e-06</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>1.299053e-06</td>\n",
       "      <td>0.00252525</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002525253272727273}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000749</td>\n",
       "      <td>4.431636e-06</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>8.492355e-07</td>\n",
       "      <td>0.00262626</td>\n",
       "      <td>{'gnb__var_smoothing': 0.002626263363636364}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>2.154854e-06</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>1.944245e-06</td>\n",
       "      <td>0.00272727</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0027272734545454548}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>2.011602e-06</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>8.915030e-06</td>\n",
       "      <td>0.00282828</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0028282835454545457}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.958941</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.221532e-06</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>3.105734e-05</td>\n",
       "      <td>0.00292929</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0029292936363636366}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956223</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.410503e-06</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1.446024e-05</td>\n",
       "      <td>0.0030303</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0030303037272727275}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.956223</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>4.256206e-06</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>1.453914e-06</td>\n",
       "      <td>0.00313131</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0031313138181818185}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.953506</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000932</td>\n",
       "      <td>1.456809e-04</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>3.116929e-04</td>\n",
       "      <td>0.00323232</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0032323239090909094}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.953506</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000790</td>\n",
       "      <td>3.208502e-05</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>2.722902e-05</td>\n",
       "      <td>0.00333333</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0033333340000000003}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000786</td>\n",
       "      <td>3.859008e-05</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>1.267212e-06</td>\n",
       "      <td>0.00343434</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0034343440909090912}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.101187e-05</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>6.931587e-06</td>\n",
       "      <td>0.00353535</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003535354181818182}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000810</td>\n",
       "      <td>1.088644e-04</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>1.070762e-05</td>\n",
       "      <td>0.00363636</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003636364272727273}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000807</td>\n",
       "      <td>5.377155e-05</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>8.646060e-05</td>\n",
       "      <td>0.00373737</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003737374363636364}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000845</td>\n",
       "      <td>1.101012e-04</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>1.311356e-05</td>\n",
       "      <td>0.00383838</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003838384454545455}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>1.765344e-05</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>3.502375e-05</td>\n",
       "      <td>0.00393939</td>\n",
       "      <td>{'gnb__var_smoothing': 0.003939394545454546}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>1.922796e-04</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>1.359652e-05</td>\n",
       "      <td>0.0040404</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004040404636363637}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000785</td>\n",
       "      <td>4.211869e-05</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>5.633191e-06</td>\n",
       "      <td>0.00414141</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0041414147272727285}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000768</td>\n",
       "      <td>8.783347e-06</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>5.004675e-05</td>\n",
       "      <td>0.00424242</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004242424818181819}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000753</td>\n",
       "      <td>1.412253e-05</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>9.333410e-06</td>\n",
       "      <td>0.00434343</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0043434349090909095}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000775</td>\n",
       "      <td>6.518590e-05</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>1.772685e-05</td>\n",
       "      <td>0.00444445</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004444445000000001}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>1.364413e-06</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>2.289160e-06</td>\n",
       "      <td>0.00454546</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004545455090909092}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>1.220077e-06</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>1.352645e-06</td>\n",
       "      <td>0.00464647</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004646465181818183}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950788</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000757</td>\n",
       "      <td>2.852417e-05</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>2.372235e-06</td>\n",
       "      <td>0.00474748</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004747475272727273}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.948041</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>2.085311e-06</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>3.415715e-06</td>\n",
       "      <td>0.00484849</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0048484853636363645}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000766</td>\n",
       "      <td>4.594401e-05</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>4.582892e-05</td>\n",
       "      <td>0.0049495</td>\n",
       "      <td>{'gnb__var_smoothing': 0.004949495454545456}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.843585e-06</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>1.663600e-06</td>\n",
       "      <td>0.00505051</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005050505545454546}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000738</td>\n",
       "      <td>1.755051e-06</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>2.251604e-06</td>\n",
       "      <td>0.00515152</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005151515636363637}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000752</td>\n",
       "      <td>2.486100e-05</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>2.241919e-05</td>\n",
       "      <td>0.00525253</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005252525727272728}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>1.110312e-06</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>1.795080e-06</td>\n",
       "      <td>0.00535354</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00535353581818182}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.660393e-06</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1.572479e-06</td>\n",
       "      <td>0.00545455</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00545454590909091}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000767</td>\n",
       "      <td>4.837823e-05</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>4.470313e-05</td>\n",
       "      <td>0.00555556</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0055555560000000006}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>1.319661e-05</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>2.162261e-06</td>\n",
       "      <td>0.00565657</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005656566090909092}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>2.846083e-06</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>9.386549e-07</td>\n",
       "      <td>0.00575758</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005757576181818183}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.154962e-05</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>1.029800e-04</td>\n",
       "      <td>0.00585859</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005858586272727274}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000753</td>\n",
       "      <td>8.562140e-06</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>4.082374e-06</td>\n",
       "      <td>0.0059596</td>\n",
       "      <td>{'gnb__var_smoothing': 0.005959596363636364}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>1.539370e-06</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>8.601436e-05</td>\n",
       "      <td>0.00606061</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006060606454545456}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000746</td>\n",
       "      <td>7.853350e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>2.628017e-06</td>\n",
       "      <td>0.00616162</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006161616545454547}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>4.460403e-07</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.802979e-06</td>\n",
       "      <td>0.00626263</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0062626266363636374}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.000762</td>\n",
       "      <td>3.359292e-05</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>4.768442e-05</td>\n",
       "      <td>0.00636364</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006363636727272728}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>1.039242e-06</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>1.353957e-06</td>\n",
       "      <td>0.00646465</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006464646818181819}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.196555e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.220077e-06</td>\n",
       "      <td>0.00656566</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006565656909090911}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000765</td>\n",
       "      <td>3.140005e-05</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>1.880146e-06</td>\n",
       "      <td>0.00666667</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006666667000000001}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000743</td>\n",
       "      <td>2.416011e-06</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>5.930587e-07</td>\n",
       "      <td>0.00676768</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006767677090909092}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000752</td>\n",
       "      <td>1.470146e-05</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>1.501990e-06</td>\n",
       "      <td>0.00686869</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006868687181818183}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>1.061482e-05</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.802979e-06</td>\n",
       "      <td>0.0069697</td>\n",
       "      <td>{'gnb__var_smoothing': 0.006969697272727274}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.616594e-05</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>4.915125e-07</td>\n",
       "      <td>0.00707071</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007070707363636365}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.148067e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.940587e-06</td>\n",
       "      <td>0.00717172</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007171717454545455}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000812</td>\n",
       "      <td>4.162112e-05</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>1.265810e-06</td>\n",
       "      <td>0.00727273</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007272727545454547}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>1.474537e-06</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>8.323336e-07</td>\n",
       "      <td>0.00737374</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007373737636363638}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000767</td>\n",
       "      <td>3.897360e-05</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.123134e-04</td>\n",
       "      <td>0.00747475</td>\n",
       "      <td>{'gnb__var_smoothing': 0.0074747477272727285}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.945294</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000824</td>\n",
       "      <td>8.786677e-05</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>2.363446e-04</td>\n",
       "      <td>0.00757576</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007575757818181819}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000765</td>\n",
       "      <td>1.919779e-05</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>7.342644e-05</td>\n",
       "      <td>0.00767677</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00767676790909091}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000849</td>\n",
       "      <td>1.080772e-04</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>6.853225e-05</td>\n",
       "      <td>0.00777778</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007777778000000002}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000887</td>\n",
       "      <td>1.509980e-04</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>7.561504e-05</td>\n",
       "      <td>0.00787879</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00787878809090909}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000796</td>\n",
       "      <td>2.731142e-05</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>7.053272e-06</td>\n",
       "      <td>0.0079798</td>\n",
       "      <td>{'gnb__var_smoothing': 0.007979798181818182}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000764</td>\n",
       "      <td>2.025681e-06</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>3.271139e-05</td>\n",
       "      <td>0.00808081</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008080808272727273}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000816</td>\n",
       "      <td>8.305926e-05</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>3.928484e-06</td>\n",
       "      <td>0.00818182</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008181818363636364}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.000761</td>\n",
       "      <td>1.560902e-05</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>6.232993e-05</td>\n",
       "      <td>0.00828283</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008282828454545456}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.929571e-06</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>1.276987e-06</td>\n",
       "      <td>0.00838384</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008383838545454545}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.940587e-06</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>4.588594e-05</td>\n",
       "      <td>0.00848485</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008484848636363637}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.482946e-06</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>3.026150e-05</td>\n",
       "      <td>0.00858586</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008585858727272728}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.530917e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>2.665601e-06</td>\n",
       "      <td>0.00868687</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008686868818181818}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.000764</td>\n",
       "      <td>3.544568e-05</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>1.541492e-05</td>\n",
       "      <td>0.00878788</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00878787890909091}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000743</td>\n",
       "      <td>2.817856e-06</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.649779e-05</td>\n",
       "      <td>0.00888889</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008888889}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>2.307708e-06</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>7.633119e-07</td>\n",
       "      <td>0.0089899</td>\n",
       "      <td>{'gnb__var_smoothing': 0.008989899090909092}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>4.825768e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>7.420718e-07</td>\n",
       "      <td>0.00909091</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009090909181818183}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>1.363815e-04</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>9.841510e-05</td>\n",
       "      <td>0.00919192</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009191919272727273}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000781</td>\n",
       "      <td>6.796966e-05</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>2.625312e-06</td>\n",
       "      <td>0.00929293</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009292929363636364}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>4.923531e-05</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>9.474372e-05</td>\n",
       "      <td>0.00939394</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009393939454545456}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.787146e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.474537e-06</td>\n",
       "      <td>0.00949495</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009494949545454545}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>1.123038e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.364413e-06</td>\n",
       "      <td>0.00959596</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009595959636363637}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>3.048590e-06</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>3.451413e-05</td>\n",
       "      <td>0.00969697</td>\n",
       "      <td>{'gnb__var_smoothing': 0.009696969727272728}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.763129e-06</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>5.161914e-07</td>\n",
       "      <td>0.00979798</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00979797981818182}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000743</td>\n",
       "      <td>2.526000e-06</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>1.787146e-06</td>\n",
       "      <td>0.00989899</td>\n",
       "      <td>{'gnb__var_smoothing': 0.00989898990909091}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000819</td>\n",
       "      <td>1.215192e-04</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>2.445244e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gnb__var_smoothing': 0.01}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('gnb', GaussianNB())])\n",
    "\n",
    "parameter_grid = { 'gnb__var_smoothing': np.linspace(start=1e-9, stop=1e-2, num=100)}\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold)\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorurile rezultate in urma 5-fold cross validation: [0.98648649 0.98630137 0.97260274 0.95890411 0.95890411]\n",
      "Media scorurilor: 0.9726397630507219\n",
      "Cel mai bun set de parametri: {'mlp__activation': 'identity', 'mlp__alpha': 0.010204081632653062}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_mlp__activation</th>\n",
       "      <th>param_mlp__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481432</td>\n",
       "      <td>0.066465</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>5.095064e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.427364</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>4.944596e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.398370</td>\n",
       "      <td>0.069465</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>4.520732e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.433742</td>\n",
       "      <td>0.041603</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>7.289304e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.382429</td>\n",
       "      <td>0.046235</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>3.599938e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.410630</td>\n",
       "      <td>0.044936</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>5.547047e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.975275</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.372168</td>\n",
       "      <td>0.058613</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>9.389506e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>4.190961e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.438304</td>\n",
       "      <td>0.090868</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>3.962091e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.406581</td>\n",
       "      <td>0.054361</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>5.221993e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.422263</td>\n",
       "      <td>0.052994</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>2.604682e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384278</td>\n",
       "      <td>0.049309</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1.566820e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.431294</td>\n",
       "      <td>0.056724</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>5.963453e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.450766</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>5.539565e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.387342</td>\n",
       "      <td>0.033867</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1.577205e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.382584</td>\n",
       "      <td>0.050805</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>6.153726e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.424458</td>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.257907e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.047123</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1.437152e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.423063</td>\n",
       "      <td>0.038681</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>4.462008e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.424374</td>\n",
       "      <td>0.080013</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>8.069993e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.379417</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>3.750833e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.422931</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>3.909751e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.388976</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>4.890488e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.465321</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>4.985101e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.402915</td>\n",
       "      <td>0.051562</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>5.072702e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.447657</td>\n",
       "      <td>0.042803</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>5.283500e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.357379</td>\n",
       "      <td>0.018698</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>4.836431e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.421926</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>2.372235e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.343506</td>\n",
       "      <td>0.035515</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>3.425001e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.451300</td>\n",
       "      <td>0.063891</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>3.238475e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.386910</td>\n",
       "      <td>0.074934</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>3.703171e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.396665</td>\n",
       "      <td>0.056913</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>2.112394e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.417749</td>\n",
       "      <td>0.042483</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>1.069634e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.363573</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>3.581738e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.377461</td>\n",
       "      <td>0.052310</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>9.748048e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.403545</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>4.987951e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.437056</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>8.288244e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.431513</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>7.059314e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.392625</td>\n",
       "      <td>0.036064</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1.095867e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.360207</td>\n",
       "      <td>0.058713</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>5.470654e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.398796</td>\n",
       "      <td>0.042025</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>3.165226e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.418942</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>2.289936e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.423562</td>\n",
       "      <td>0.063993</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>7.422040e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.449795</td>\n",
       "      <td>0.045185</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>4.136408e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.422695</td>\n",
       "      <td>0.075148</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>4.314763e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.448536</td>\n",
       "      <td>0.066003</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>5.564342e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.443649</td>\n",
       "      <td>0.051371</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>1.169285e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.422543</td>\n",
       "      <td>0.056703</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>3.361971e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.410562</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>1.969661e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.370457</td>\n",
       "      <td>0.045873</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>6.158643e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'identity', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.593417</td>\n",
       "      <td>0.060212</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>5.795754e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.606790</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>9.673700e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.647028</td>\n",
       "      <td>0.093668</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1.282968e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.629314</td>\n",
       "      <td>0.111722</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>4.384488e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.558515</td>\n",
       "      <td>0.083256</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>5.008277e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.595962</td>\n",
       "      <td>0.067685</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>6.123353e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.560250</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>8.457265e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.532811</td>\n",
       "      <td>0.049605</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>7.234354e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.592646</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>4.624644e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.540958</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>1.898911e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.541491</td>\n",
       "      <td>0.077970</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>1.864968e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.562186</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>4.757556e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.560585</td>\n",
       "      <td>0.065954</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>8.986521e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.604794</td>\n",
       "      <td>0.024807</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>6.988743e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.589917</td>\n",
       "      <td>0.100115</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>7.492899e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.580535</td>\n",
       "      <td>0.065655</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1.368300e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.549401</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>6.824146e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.561409</td>\n",
       "      <td>0.074123</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>8.383728e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.072862</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>3.652457e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.517281</td>\n",
       "      <td>0.054899</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>4.910681e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.623971</td>\n",
       "      <td>0.068573</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>7.739199e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.666457</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>1.016942e-04</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.536734</td>\n",
       "      <td>0.079405</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>5.529599e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.572651</td>\n",
       "      <td>0.072420</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>3.516169e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.543690</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>2.370617e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.515254</td>\n",
       "      <td>0.025840</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>1.722358e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.975275</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.576050</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>6.538877e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.598173</td>\n",
       "      <td>0.072051</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>3.750833e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.975275</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.541680</td>\n",
       "      <td>0.072880</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>1.746935e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.560104</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>3.144957e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.553618</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>2.857917e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.624337</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>9.788781e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.515756</td>\n",
       "      <td>0.059811</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>2.063001e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.546195</td>\n",
       "      <td>0.067690</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>1.010259e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.602006</td>\n",
       "      <td>0.063480</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>3.526258e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.571329</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>4.365404e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.544629</td>\n",
       "      <td>0.077535</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>3.055574e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.517314</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>4.884309e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.507996</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>2.672921e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.572313</td>\n",
       "      <td>0.075552</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>5.418452e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.561688</td>\n",
       "      <td>0.040115</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>6.977563e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.563577</td>\n",
       "      <td>0.052689</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>4.049608e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.551570</td>\n",
       "      <td>0.063294</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>2.726220e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.562760</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>3.296627e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.545149</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>6.699443e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.560162</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>3.748464e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.669481</td>\n",
       "      <td>0.135238</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.283591e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.972557</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.568996</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>5.010691e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.674663</td>\n",
       "      <td>0.096926</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>9.954640e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.649272</td>\n",
       "      <td>0.102765</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>8.072175e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__alpha': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.975275</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>6.031645e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.576453</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>7.902956e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.563131</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>5.048295e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.513233</td>\n",
       "      <td>0.112631</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>8.914982e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.433701</td>\n",
       "      <td>0.075557</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>9.429598e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.509625</td>\n",
       "      <td>0.128562</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>3.014888e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.520376</td>\n",
       "      <td>0.059370</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>6.601448e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.479599</td>\n",
       "      <td>0.079761</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>1.395564e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.505064</td>\n",
       "      <td>0.090023</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>5.769003e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.485295</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>1.575864e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.516410</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>5.260828e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.059397</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>6.597098e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.457911</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>3.378064e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.444108</td>\n",
       "      <td>0.081212</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>8.062947e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.509753</td>\n",
       "      <td>0.081907</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>8.652893e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.520989</td>\n",
       "      <td>0.089947</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>1.684904e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.505603</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>6.102011e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.512088</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>7.689886e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.437382</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>3.073543e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.432031</td>\n",
       "      <td>0.060822</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>4.627716e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.402550</td>\n",
       "      <td>0.062529</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>7.107463e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.425828</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>1.484144e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.426536</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>7.521530e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.440659</td>\n",
       "      <td>0.059558</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>6.737171e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.415521</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>6.024196e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.479500</td>\n",
       "      <td>0.055509</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>5.119064e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.424062</td>\n",
       "      <td>0.047040</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>8.819071e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.481004</td>\n",
       "      <td>0.107549</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>6.873685e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.397098</td>\n",
       "      <td>0.080772</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>4.144559e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.449903</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>6.848976e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.460125</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>3.018138e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.463911</td>\n",
       "      <td>0.044038</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>5.068134e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.435547</td>\n",
       "      <td>0.037309</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>8.823702e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.096292</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>1.233120e-04</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.458442</td>\n",
       "      <td>0.063653</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>9.371966e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.473583</td>\n",
       "      <td>0.022116</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>1.518176e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.449868</td>\n",
       "      <td>0.044159</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.053116e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.506065</td>\n",
       "      <td>0.114243</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>7.717133e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.484156</td>\n",
       "      <td>0.062548</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>3.253780e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.075388</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>6.357005e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.480470</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>5.378968e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.437041</td>\n",
       "      <td>0.028641</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>3.810112e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.449332</td>\n",
       "      <td>0.093528</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>7.271813e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.467237</td>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>6.162080e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.471226</td>\n",
       "      <td>0.045205</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.408649e-04</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.441236</td>\n",
       "      <td>0.049947</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>2.581590e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.545671</td>\n",
       "      <td>0.072831</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>7.891934e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.441078</td>\n",
       "      <td>0.045823</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>3.687307e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.105628</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>2.558838e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.481680</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>5.403680e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'tanh', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.463608</td>\n",
       "      <td>0.041883</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>3.579000e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.433597</td>\n",
       "      <td>0.083380</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>6.424164e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00204082</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0020408163265306124}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.363832</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>4.568454e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00408163</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.004081632653061225}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.344581</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>3.352198e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00612245</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.006122448979591837}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.416361</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>4.358367e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00816327</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.00816326530612245}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.485365</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>4.215743e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0102041</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.010204081632653062}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.461231</td>\n",
       "      <td>0.088329</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>5.315090e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0122449</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.012244897959183675}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.450750</td>\n",
       "      <td>0.108919</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>9.392124e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0142857</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.014285714285714287}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.397916</td>\n",
       "      <td>0.057409</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1.722358e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0163265</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0163265306122449}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.378825</td>\n",
       "      <td>0.038681</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>3.862822e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0183673</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.018367346938775512}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.371720</td>\n",
       "      <td>0.046440</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>3.842073e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.020408163265306124}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.380602</td>\n",
       "      <td>0.082605</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>2.317693e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.022448979591836737}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.421649</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>4.012592e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0244898</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.02448979591836735}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.378506</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>2.172841e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0265306</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.02653061224489796}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.378999</td>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>1.810844e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0285714</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.028571428571428574}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.373485</td>\n",
       "      <td>0.046577</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>2.807752e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0306122</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.030612244897959186}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.406117</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>3.133640e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0326531</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0326530612244898}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.418573</td>\n",
       "      <td>0.071198</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>6.896389e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0346939</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.03469387755102041}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.368282</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>1.299053e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0367347</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.036734693877551024}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.408020</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>1.435470e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0387755</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.03877551020408164}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.389964</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.512596e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0408163</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04081632653061225}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.390965</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>5.810765e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0428571</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04285714285714286}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.365023</td>\n",
       "      <td>0.032892</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>3.392756e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04489795918367347}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.410198</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>1.611531e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0469388</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.04693877551020409}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.385741</td>\n",
       "      <td>0.060939</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>6.084055e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0489796</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0489795918367347}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.399142</td>\n",
       "      <td>0.049592</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>1.220077e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0510204</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05102040816326531}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.397111</td>\n",
       "      <td>0.060283</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>3.359080e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0530612</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05306122448979592}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.395620</td>\n",
       "      <td>0.071390</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>2.185142e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05510204081632654}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.414271</td>\n",
       "      <td>0.088346</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>2.115755e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0571429</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05714285714285715}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.400234</td>\n",
       "      <td>0.050266</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>6.848052e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0591837</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.05918367346938776}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.391044</td>\n",
       "      <td>0.048303</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>2.112394e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.06122448979591837}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.380956</td>\n",
       "      <td>0.050425</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>2.008836e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0632653</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.06326530612244899}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.381969</td>\n",
       "      <td>0.048529</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>4.000178e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0653061</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0653061224489796}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.415198</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>2.788071e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0673469</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0673469387755102}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.414025</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>2.998653e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0693878</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.06938775510204082}</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.411138</td>\n",
       "      <td>0.071650</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>4.851100e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07142857142857144}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.385927</td>\n",
       "      <td>0.062093</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>2.907827e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0734694</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07346938775510205}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.374472</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>2.280608e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0755102</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07551020408163266}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.356189</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>3.426101e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07755102040816328}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.387141</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>7.451057e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0795918</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.07959183673469389}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.381684</td>\n",
       "      <td>0.040524</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>3.710838e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0816326530612245}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.397902</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>2.842960e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0836735</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0836734693877551}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.383752</td>\n",
       "      <td>0.086281</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>5.205776e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0857143</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.08571428571428572}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.396977</td>\n",
       "      <td>0.026773</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>4.783250e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0877551</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.08775510204081634}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.396097</td>\n",
       "      <td>0.082589</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>3.162194e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0897959</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.08979591836734695}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.969870</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.419236</td>\n",
       "      <td>0.101670</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>5.627828e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.09183673469387756}</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.364779</td>\n",
       "      <td>0.056082</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>4.381245e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0938776</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.09387755102040818}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.416131</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.097438e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0959184</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.09591836734693879}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.392924</td>\n",
       "      <td>0.060148</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>2.397404e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0979592</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.0979591836734694}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.964405</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.335736</td>\n",
       "      <td>0.040891</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>2.457562e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'mlp__activation': 'relu', 'mlp__alpha': 0.1}</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.967123</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([('mlp', MLPClassifier(max_iter= 1000))])\n",
    "\n",
    "parameter_grid = { 'mlp__alpha': np.linspace(start=0, stop=1e-1, num=50),\n",
    "                  'mlp__activation': ['identity', 'logistic', 'tanh', 'relu']\n",
    "                 }\n",
    "\n",
    "grid_search =GridSearchCV(pipe, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(grid_search, X, y, cv=strat_k_fold )\n",
    "\n",
    "print(\"Scorurile rezultate in urma 5-fold cross validation:\",scores)\n",
    "print(\"Media scorurilor:\",scores.mean())\n",
    "grid_search.fit(X, y)\n",
    "print(\"Cel mai bun set de parametri:\",grid_search.best_params_)\n",
    "grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "display(HTML(grid_search.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
