{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wi-Fi localization. Modele de clasificare\n",
    "\n",
    "Sîrbu Matei-Dan, _grupa 10LF383_\n",
    "\n",
    "<i>Sursă dataset:</i> http://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization\n",
    "\n",
    "<i>Descriere dataset:</i> [DOI 10.1007/978-981-10-3322-3_27 via ResearchGate](Docs/chp_10.1007_978-981-10-3322-3_27.pdf)\n",
    "\n",
    "<i>Synopsis:</i> Setul de date _Wireless Indoor Localization_ cuprinde 2000 de măsurători ale puterii semnalului (măsurat în dBm) recepționat de la routerele unui birou din Pittsburgh. Acest birou are șapte routere și patru camere; un utilizator înregistrează cu ajutorul unui smartphone o dată pe secundă puterea semnalelor venite de la cele șapte routere, fiecărei înregistrări fiindu-i asociate camera în care se afla utilizatorul la momentul măsurării (1, 2, 3 sau 4).\n",
    "\n",
    "În figura de mai jos este ilustrat un sample din dataset: <br><br>\n",
    "![Sample](./Images/wifi_localization_sample.png)\n",
    "\n",
    "În cele ce urmează, coloana Class (camera) este reprezentată de y, iar coloanele WS1 - WS7 (features: puterea semnalului de la fiecare router), de X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Dataset overview:</i>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS1</th>\n",
       "      <th>WS2</th>\n",
       "      <th>WS3</th>\n",
       "      <th>WS4</th>\n",
       "      <th>WS5</th>\n",
       "      <th>WS6</th>\n",
       "      <th>WS7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64</td>\n",
       "      <td>-56</td>\n",
       "      <td>-61</td>\n",
       "      <td>-66</td>\n",
       "      <td>-71</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-68</td>\n",
       "      <td>-57</td>\n",
       "      <td>-61</td>\n",
       "      <td>-65</td>\n",
       "      <td>-71</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-63</td>\n",
       "      <td>-60</td>\n",
       "      <td>-60</td>\n",
       "      <td>-67</td>\n",
       "      <td>-76</td>\n",
       "      <td>-85</td>\n",
       "      <td>-84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-61</td>\n",
       "      <td>-60</td>\n",
       "      <td>-68</td>\n",
       "      <td>-62</td>\n",
       "      <td>-77</td>\n",
       "      <td>-90</td>\n",
       "      <td>-80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-63</td>\n",
       "      <td>-65</td>\n",
       "      <td>-60</td>\n",
       "      <td>-63</td>\n",
       "      <td>-77</td>\n",
       "      <td>-81</td>\n",
       "      <td>-87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-59</td>\n",
       "      <td>-59</td>\n",
       "      <td>-48</td>\n",
       "      <td>-66</td>\n",
       "      <td>-50</td>\n",
       "      <td>-86</td>\n",
       "      <td>-94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-59</td>\n",
       "      <td>-56</td>\n",
       "      <td>-50</td>\n",
       "      <td>-62</td>\n",
       "      <td>-47</td>\n",
       "      <td>-87</td>\n",
       "      <td>-90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-62</td>\n",
       "      <td>-59</td>\n",
       "      <td>-46</td>\n",
       "      <td>-65</td>\n",
       "      <td>-45</td>\n",
       "      <td>-87</td>\n",
       "      <td>-88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-62</td>\n",
       "      <td>-58</td>\n",
       "      <td>-52</td>\n",
       "      <td>-61</td>\n",
       "      <td>-41</td>\n",
       "      <td>-90</td>\n",
       "      <td>-85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-59</td>\n",
       "      <td>-50</td>\n",
       "      <td>-45</td>\n",
       "      <td>-60</td>\n",
       "      <td>-45</td>\n",
       "      <td>-88</td>\n",
       "      <td>-87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WS1  WS2  WS3  WS4  WS5  WS6  WS7  Class\n",
       "0     -64  -56  -61  -66  -71  -82  -81      1\n",
       "1     -68  -57  -61  -65  -71  -85  -85      1\n",
       "2     -63  -60  -60  -67  -76  -85  -84      1\n",
       "3     -61  -60  -68  -62  -77  -90  -80      1\n",
       "4     -63  -65  -60  -63  -77  -81  -87      1\n",
       "...   ...  ...  ...  ...  ...  ...  ...    ...\n",
       "1995  -59  -59  -48  -66  -50  -86  -94      4\n",
       "1996  -59  -56  -50  -62  -47  -87  -90      4\n",
       "1997  -62  -59  -46  -65  -45  -87  -88      4\n",
       "1998  -62  -58  -52  -61  -41  -90  -85      4\n",
       "1999  -59  -50  -45  -60  -45  -88  -87      4\n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = ['WS1', 'WS2', 'WS3', 'WS4', 'WS5', 'WS6', 'WS7', 'Class']\n",
    "data_wifi = pd.read_csv(\"./Datasets/wifi_localization.txt\", names=header, sep='\\t')\n",
    "display(HTML(\"<i>Dataset overview:</i>\"))\n",
    "display(data_wifi)\n",
    "X = data_wifi.values[:, :7]\n",
    "y = data_wifi.values[:, -1]\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele de clasificare\n",
    "### [1. <i>k</i>-nearest neighbors classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.neighbors.KNeighborsClassifier`<i>(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for 4-nearest neighbors classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: [0.965  0.98   0.975  0.9825 0.985 ] \n",
      "=> Average test accuracy: 97.75%\n",
      "Train accuracy: [0.993125 0.991875 0.993125 0.99     0.99125 ] \n",
      "=> Average train accuracy: 99.188%\n",
      "Test F1 score: [0.96489838 0.97996795 0.97488398 0.98255407 0.98503657] \n",
      "=> Average test F1 score: 97.747%\n",
      "Train F1 score: [0.99311709 0.99188648 0.99312342 0.98998978 0.99124912] \n",
      "=> Average train F1 score: 99.187%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# hiperparametri\n",
    "knn_neighbors = 4\n",
    "\n",
    "# implementare KNN\n",
    "model = KNeighborsClassifier(n_neighbors=knn_neighbors)\n",
    "model_acc = cross_validate(model, X, y, cv=folds, scoring='accuracy', return_train_score=True)\n",
    "model_f1 = cross_validate(model, X, y, cv=folds, scoring='f1_macro', return_train_score=True)\n",
    "\n",
    "# statistici\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for {knn_neighbors}-nearest neighbors classification:</h4>\"))\n",
    "print(f\"Test accuracy: {model_acc['test_score']} \\n=> Average test accuracy: {round(model_acc['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train accuracy: {model_acc['train_score']} \\n=> Average train accuracy: {round(model_acc['train_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Test F1 score: {model_f1['test_score']} \\n=> Average test F1 score: {round(model_f1['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train F1 score: {model_f1['train_score']} \\n=> Average train F1 score: {round(model_f1['train_score'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2. Decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.tree.DecisionTreeClassifier`<i>(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Decision Trees classification:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: [0.96   0.9325 0.9275 0.9825 0.9725] \n",
      "=> Average test accuracy: 95.5%\n",
      "Train accuracy: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score: [0.95972496 0.93246313 0.92562893 0.98251804 0.97253289] \n",
      "=> Average test F1 score: 95.457%\n",
      "Train F1 score: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# implementare decision trees\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model_acc = cross_validate(model, X, y, cv=folds, scoring='accuracy', return_train_score=True)\n",
    "model_f1 = cross_validate(model, X, y, cv=folds, scoring='f1_macro', return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Decision Trees classification:</h4>\"))\n",
    "print(f\"Test accuracy: {model_acc['test_score']} \\n=> Average test accuracy: {round(model_acc['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train accuracy: {model_acc['train_score']} \\n=> Average train accuracy: {round(model_acc['train_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Test F1 score: {model_f1['test_score']} \\n=> Average test F1 score: {round(model_f1['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train F1 score: {model_f1['train_score']} \\n=> Average train F1 score: {round(model_f1['train_score'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3. Multilayer perceptron (MLP) classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.neural_network.MLPClassifier`<i>(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for MLP classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "using hyperparameters - Solver: <b>adam</b>, Activation function: <b>relu</b>, Parameter for regularization (α): <b>0.001</b>, Hidden layer sizes: <b>(50, 50)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: [0.9725 0.9975 0.95   0.975  0.9775] \n",
      "=> Average test accuracy: 97.45%\n",
      "Train accuracy: [0.98125  0.971875 0.983125 0.98125  0.981875] \n",
      "=> Average train accuracy: 97.988%\n",
      "Test F1 score: [0.97244414 0.99749994 0.94983905 0.97514624 0.97746665] \n",
      "=> Average test F1 score: 97.448%\n",
      "Train F1 score: [0.98124085 0.97171261 0.98314044 0.98122406 0.9819253 ] \n",
      "=> Average train F1 score: 97.985%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Solvere pentru optimizarea ponderilor:\n",
    "# - lbfgs (quasi-Newton optimizer\n",
    "# - sgd (stochastic gradient descent)\n",
    "# - adam (stochastic gradient descent by Kingma, Diederik and Jimmy Ba)\n",
    "#\n",
    "# Funcții de activare pentru stratul ascuns:\n",
    "# - identity (linear)\n",
    "# - logistic (sigmoid)\n",
    "# - tanh (hyperbolic tangent)\n",
    "# - relu (rectified linear unit)\n",
    "\n",
    "# hiperparametri\n",
    "mlp_solver = 'adam'\n",
    "mlp_activation = 'relu'\n",
    "mlp_alpha=1e-3\n",
    "mlp_hidden_layer_sizes = (50,50)\n",
    "\n",
    "model = MLPClassifier(solver=mlp_solver, activation=mlp_activation, alpha=mlp_alpha, hidden_layer_sizes=mlp_hidden_layer_sizes, random_state=42)\n",
    "\n",
    "model_acc = cross_validate(model, X, y, cv=folds, scoring='accuracy', return_train_score=True)\n",
    "model_f1 = cross_validate(model, X, y, cv=folds, scoring='f1_macro', return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for MLP classification</h4>\"))\n",
    "display(HTML(f\"using hyperparameters - Solver: <b>{mlp_solver}</b>, Activation function: <b>{mlp_activation}</b>, Parameter for regularization (α): <b>{mlp_alpha}</b>, Hidden layer sizes: <b>{mlp_hidden_layer_sizes}</b>\"))\n",
    "print(f\"\\nTest accuracy: {model_acc['test_score']} \\n=> Average test accuracy: {round(model_acc['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train accuracy: {model_acc['train_score']} \\n=> Average train accuracy: {round(model_acc['train_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Test F1 score: {model_f1['test_score']} \\n=> Average test F1 score: {round(model_f1['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train F1 score: {model_f1['train_score']} \\n=> Average train F1 score: {round(model_f1['train_score'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4. Gaussian Naïve Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.naive_bayes.GaussianNB`<i>(priors=None, var_smoothing=1e-09)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmul de clasificare _Gaussian Naïve Bayes_ aparține familiei de clasificatori _Naïve Bayes_, care presupun că prezența unui feature într-o clasă nu este afectată de prezența altor features; pe scurt, proprietățile contribuie independent la probabilitatea apartenenței la o clasă. În particular, algoritmul _Gaussian Naïve Bayes_ urmează funcția de probabilitate (PDF) a unei distribuții normale (Gaussiene):\n",
    "$$\\large P(x_i | y) = \\frac{1}{\\sqrt{2 \\pi \\sigma_y^2}} \\exp \\bigg(-\\frac{(x_i - \\mu_y)^2}{2 \\sigma_y^2}\\bigg),$$\n",
    "unde parametrii $\\sigma_y$ și $\\mu_y$, deviația standard și media, sunt determinați folosind maximum likelihood estimation (MLE), o metodă de estimare a parametrilor unei PDF prin maximizarea unei funcții de likelihood (cât de bine se potrivește un sample cu un model statistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Gaussian NB classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: [0.99   0.9725 0.98   0.98   0.985 ] \n",
      "=> Average test accuracy: 98.15%\n",
      "Train accuracy: [0.98125  0.983125 0.9875   0.985    0.983125] \n",
      "=> Average train accuracy: 98.4%\n",
      "Test F1 score: [0.99001188 0.97255265 0.9799862  0.98006098 0.9849985 ] \n",
      "=> Average test F1 score: 98.152%\n",
      "Train F1 score: [0.98127765 0.98313802 0.98751983 0.98501642 0.9831722 ] \n",
      "=> Average train F1 score: 98.402%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model_acc = cross_validate(model, X, y, cv=folds, scoring='accuracy', return_train_score=True)\n",
    "model_f1 = cross_validate(model, X, y, cv=folds, scoring='f1_macro', return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Gaussian NB classification</h4>\"))\n",
    "print(f\"\\nTest accuracy: {model_acc['test_score']} \\n=> Average test accuracy: {round(model_acc['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train accuracy: {model_acc['train_score']} \\n=> Average train accuracy: {round(model_acc['train_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Test F1 score: {model_f1['test_score']} \\n=> Average test F1 score: {round(model_f1['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train F1 score: {model_f1['train_score']} \\n=> Average train F1 score: {round(model_f1['train_score'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5. Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.ensemble.RandomForestClassifier`<i>(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clasificator _Random forest_ se folosește de ipotezele emise de mai mulți _random trees_ (arbori de decizie aleatori), obținuți în urma unui _random split_. Un _random forest_ se obține prin construirea unui _random tree_ pentru fiecare set de antrenare. Acești arbori funcționează ca un ansamblu; pentru fiecare dată de intrare se aplică modelele din ansamblu, și rezultatul final se obține agregând rezultatele prin votare.\n",
    "<div style=\"text-align:center\"><img style=\"width: 400px\" src=\"./Images/wifi_rf_diagram.png\"><br>Un model random forest făcând o predicție; în urma votării se obține rezultatul 1.<br>sursă: Medium (Towards Data Science: Understanding Random Forest)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>5-fold cross validation for Random Forest classification</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: [0.985  0.95   0.975  0.985  0.9875] \n",
      "=> Average test accuracy: 97.65%\n",
      "Train accuracy: [1. 1. 1. 1. 1.] \n",
      "=> Average train accuracy: 100.0%\n",
      "Test F1 score: [0.9874995  0.96228787 0.97494678 0.9850456  0.98749969] \n",
      "=> Average test F1 score: 97.946%\n",
      "Train F1 score: [1. 1. 1. 1. 1.] \n",
      "=> Average train F1 score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_n_estimators = 150\n",
    "rfc_criterion = 'gini' # 'gini' sau 'entropy'\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=rfc_n_estimators, criterion=rfc_criterion)\n",
    "model_acc = cross_validate(model, X, y, cv=folds, scoring='accuracy', return_train_score=True)\n",
    "model_f1 = cross_validate(model, X, y, cv=folds, scoring='f1_macro', return_train_score=True)\n",
    "\n",
    "display(HTML(f\"<h4>{folds}-fold cross validation for Random Forest classification</h4>\"))\n",
    "print(f\"\\nTest accuracy: {model_acc['test_score']} \\n=> Average test accuracy: {round(model_acc['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train accuracy: {model_acc['train_score']} \\n=> Average train accuracy: {round(model_acc['train_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Test F1 score: {model_f1['test_score']} \\n=> Average test F1 score: {round(model_f1['test_score'].mean() * 100, 3)}%\")\n",
    "print(f\"Train F1 score: {model_f1['train_score']} \\n=> Average train F1 score: {round(model_f1['train_score'].mean() * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i> TODO: classification algorithms descriptions and nested cross validation for optimizing hyperparameters </i>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
