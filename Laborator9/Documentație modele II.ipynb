{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentație modele\n",
    "\n",
    "Tătaru Dragoș-Cătălin, grupa _10LF383_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.linear_model.Ridge`<i>(alpha=1.0, *, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriere\n",
    "\n",
    "Modelul este folosit pentru estimări când datele au multe dimensiuni dar un număr restrâns de intrări pentru fiecare dimensiune.\n",
    "\n",
    "În general, modelul Ridge Regression are o performanță mai scăzută pe setul de date folosit pentru antrenare comparativ cu Linear Regression, dar o putere mai mare de predicție pentru setul de date de testare, iar acest lucru se datorează penalizării suplimentare pe care o aplică sumei pătratelor datorate erorilor. \n",
    "Prin aplicarea acestei penalizări modelul evită sa fie mult prea fidel construit pe datele din setul de instruire (“overfitting”). </h3>\n",
    "\n",
    "<img style=\"height: 50px; width:325px\" src=\"Images/RidgeFormula.png\" >\n",
    "\n",
    "Hiperparametrul $\\alpha$ controlează cantitatea de penalizare, ia valori egale sau mai mari ca 0, cu cât este mai mare penalizarea, cu atât coeficienții tind mai mult spre coliniaritate:\n",
    "<sup>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification\">[1]</a>\n",
    "</sup>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img style=\"height: 250px; width:400px\" src=\"Images/Ridge1.png\" ></td>\n",
    "    <td><img style=\"height: 250px; width:400px\" src=\"Images/Ridge2.png\"></td>\n",
    "    <td><img style=\"height: 250px; width:400x\" src=\"Images/Ridge3.png\" ></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img style=\"height: 250px; width:400x\" src=\"Images/Ridge4.png\"></td>\n",
    "    <td><img style=\"height: 250px; width:400x\" src=\"Images/Ridge5.png\" ></td>\n",
    "  </tr>\n",
    "  <tr> \n",
    "     <td colspan=\"3\"><p><center>Imagini preluate din tutorialul \"Regularization Part 1: Ridge Regression\"\n",
    "         <sup>\n",
    "            <a href=\"https://www.youtube.com/watch?v=Q81RR3yKn30\">[2]</a>\n",
    "          </sup>oferit de \"StatQuest with Josh Starmer\"</center></p> \n",
    "      </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametri\n",
    "- `alpha`: \"Regularization strength\", reduce eroarea estimărilor, valori mai mari înseamnă regularizări mai puternice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [LassoLars Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.linear_model.LassoLars`<i>(alpha=1.0, *, fit_intercept=True, verbose=False, normalize=True, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False, jitter=None, random_state=None)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Despre regresor\n",
    "\n",
    "Modelul LassoLars este un algoritm de tipul Least Angle Regression (Lars) ce implementează o regresie Lasso. \n",
    "Este un algoritm folosit pentru seturile de date cu multe dimensiuni și a fost dezvoltat de Bradley Efron, Trevor Hastie, Iain Johnstone și Robert Tibshirani<sup><a href=\"https://en.wikipedia.org/wiki/Least-angle_regression\">[3]</a></sup>. Algoritmul este similar cu \"Forward Stepwise Regression\". \n",
    "\n",
    "\"Forward Stepwise Regression\" este o variantă îmbunătățită a algoritmului \"Forward Selection\". Acesta din urmă  cauta să obtina o predictie adecvată adăugând la fiecare pas în model variabila cu corelația cea mai puternică pentru variabila prezisă, dar în acest fel sunt neglijați ceilalți predictori corelați cu variabila adăugată și ignorați pentru că nu cresc prea mult predicția modelului. \"Forward Stepwise Regression\" în schimb face modificări de pondere la fiecare pas variabilelor adăugate în model pe masură ce sunt adaugate și alte variabile.\n",
    "\n",
    "\"Least Angle Regression\" este în schimb mai rapid decât \"Forward Stepwise Regression\" întrucat alege să facă schimbări în direcția optimă așa încât corelațiile dintre variabilele din model să fie egale.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"Images/LassoLars.png\" >\n",
    "<p><center>Least Angle Regression\n",
    "    <sup>\n",
    "        <a href=\"https://www.quora.com/What-is-Least-Angle-Regression-and-when-should-it-be-used\">[4]</a>\n",
    "    </sup>\n",
    "    </center>\n",
    "</p>\n",
    "</div>\n",
    "    \n",
    "### Descriere funcționare algoritm:\n",
    "\n",
    "Modelul pornește din μ0. Se caută variabila care corelează cel mai puternic cu y, sau altfel spus variabila față de care y descrie cel mai mic unghi (linia verde), în cazul de față x1. Algoritmul se deplasează în direcția variabilei x1 până când unghiul lui y față de x2 devine egal cu unghiul dintre y si x1, sau altfel spus când se ajunge la corelații egale (μ1). Din acest punct algoritmul sa va deplasa în direcția cea mai potrivită pentru a conserva egalitatea corelațiilor. Pe parcurs vor fi adăugate și alte variabile x3 si algoritmul se va deplasa într-o directie care să aducă cele 3 corelații la egalitate. Acest proces va continua până cand sunt epuizate toate variabilele.<sup><a href=\"https://www.quora.com/What-is-Least-Angle-Regression-and-when-should-it-be-used\">[5]</a></sup>\n",
    "    \n",
    "### Hiperparametri\n",
    "- `alpha`: constantă care se înmulțește cu termenul de penalizare, implicit 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [Stochastic Gradient Descent Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.linear_model.SGDRegressor`<i>(loss='squared_loss', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000,tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01,power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriere\n",
    "\n",
    "Este un model liniar de regresie ce folosește Stochastic Gradient Descent pentru normalizarea funcției de eroare. \n",
    "Poate să fie utilizat cu un anumit tip al funcției de eroare, implementată ca și hiperparametru în cadrul modelului.\n",
    "\n",
    "Spre exemplu, modelul poate fi folosit cu funcția de eroare liniară sau pătratică. Acest lucru determină algoritmul să se axeze mai mult sau mai puțin pe corectarea valorilor aberante (outliers).\n",
    "<sup>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor\">[6]</a>\n",
    "</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/GradientDescent.png\" >\n",
    "<p><center>Gradient Descent\n",
    "    <sup>\n",
    "        <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch04.html\">[4]</a>\n",
    "    </sup>\n",
    "    </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametri\n",
    "- `loss`: funcția de loss, se poate alege între _squared_loss_, _huber_, _epsilon_insensitive_ sau _squared_epsilon_insensitive_\n",
    "- `l1_ratio`: utilizat numai dacă `penalty` este `elasticnet`, definește raportul dintre impactul fiecărui termen de penalizare asupra funcției obiectiv\n",
    "- `alpha`: constanta care multiplică termenul de regularizare."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
