{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.linear_model.Ridge`<i>(alpha=1.0, *, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modelul este folosit pentru estimari cand datele au multe dimensiuni dar un numar restrans de intrari pentru fiecare dimensiune.\n",
    "In general, modelul Ridge Regression are o performanta mai scazuta pe setul de date folosit pentru antrenare comparativ cu Linear Regression, dar o putere mai mare de predictie pentru setul de date de testare iar acest lucru se datoreaza penalizarii suplimentare pe care o aplica sumei patratelor datorate erorilor. \n",
    "Prin aplicarea acestei penalizari modelul evita sa fie mult prea fidel construit pe datele din setul de instruire “overfitting”. </h3>\n",
    "\n",
    "<img style=\"height: 50px; width:325px\" src=\"Images/RidgeFormula.png\" >\n",
    "\n",
    "<h3>Hiperparametrul $\\alpha$ controleaza cantitatea de penalizare, ia valori elage sau mai mari ca 0, cu cat este mai mare penalizarea cu atat coeficientii tind mai mult spre coliniaritate.\n",
    "<sup>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification\">[1]</a>\n",
    "</sup>\n",
    "</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <table>\n",
    "  <tr>\n",
    "    <td><img style=\"height: 250px; width:400px\" src=\"Images/Ridge1.png\" ></td>\n",
    "    <td><img style=\"height: 250px; width:400px\" src=\"Images/Ridge2.png\"></td>\n",
    "    <td><img style=\"height: 250px; width:400x\" src=\"Images/Ridge3.png\" ></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img style=\"height: 250px; width:400x\" src=\"Images/Ridge4.png\"></td>\n",
    "    <td><img style=\"height: 250px; width:400x\" src=\"Images/Ridge5.png\" ></td>\n",
    "  </tr>\n",
    "  <tr> \n",
    "     <td><p><center>Imagini preluate din tutorialul \"Regularization Part 1: Ridge Regression\"\n",
    "         <sup>\n",
    "            <a href=\"https://www.youtube.com/watch?v=Q81RR3yKn30\">[2]</a>\n",
    "          </sup>oferit de \"StatQuest with Josh Starmer\"</center></p> \n",
    "      </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LassoLars Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.linear_model.LassoLars`<i>(alpha=1.0, *, fit_intercept=True, verbose=False, normalize=True, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False, jitter=None, random_state=None)<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Modelul LassoLars este un algoritm de tipul Least Angle Regression (Lars) ce implementeaza o regresie Lasso. \n",
    "Este un algoritm folosit pentru seturile de date cu multe dimensiuni si a fost dezvoltat de Bradley Efron, Trevor Hastie, Iain Johnstone si Robert Tibshirani<sup><a href=\"https://en.wikipedia.org/wiki/Least-angle_regression\">[3]</a></sup>.. Algoritmul este similar cu \"Forward Stepwise Regression\". \n",
    "\n",
    "\"Forward Stepwise Regression\" este o varianta imbunatatita a algoritmului \"Forward Selection\". Acesta din urma  cauta sa obtina o predictie adecvata adaugand la fiecare pas in model variabila cu corelatia cea mai puternica pentru variabila prezisa,dar in acestfel fel sunt neglijati ceilalti predictori corelati cu variabila adaugata si ignorati pentru ca nu cresc prea mult predictia modelului. \"Forward Stepwise Regression\" in schimb face modificari de pondere la fiecare pas variabilelor adaugate in model pe masura ce sunt adaugate si alte variabile.\n",
    "\n",
    "\"Least Angle Regression\" este in schimb mai rapid decat \"Forward Stepwise Regression\" intrucat alege sa faca schimbari in directia optima asa incat corelatiile dintre variabilele din model sa fie egale.<h3>  \n",
    "\n",
    "\n",
    "<img src=\"Images/LassoLars.png\" >\n",
    "<p><center>Least Angle Regression\n",
    "    <sup>\n",
    "        <a href=\"https://www.quora.com/What-is-Least-Angle-Regression-and-when-should-it-be-used\">[4]</a>\n",
    "    </sup>\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "### Descriere functionare algoritm:\n",
    "<h3>Modelul porneste din μ0. Se cauta variabila care coreleaza cel mai puternic cu y sau altfel spus variabila fata de care y descrie cel mai mic unghi(linia verde), in cazul de fata x1. Algoritmul se deplaseaza in directia variabilei x1 pana cand unghiul lui y fata de x2 devine egal cu unghiul dintre y si x1 sau altfel spus cand se ajunge la corelatii egale(μ1). Din acest punct algoritmul sa va deplasa in directia cea mai potrivita pentru a conserva egalitatea corelatiilor. Pe parcurs vor fi adaugate si alte variabile x3 si algoritmul sa va deplasa intr-o directie care sa aduca cele 3 corelatii la egalitate. Acest proces va continua pana cand sunt epuizate toate variabilele. <sup><a href=\"https://www.quora.com/What-is-Least-Angle-Regression-and-when-should-it-be-used\">[5]</a></sup> <h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent SGDRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `sklearn.linear_model.SGDRegressor`<i>(loss='squared_loss', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000,tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01,power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Este un model liniar de regresie ce foloseste Stochastic Gradient Descent pentru normalizare functiei de eroare. \n",
    "Poate sa fie utilizat cu un anumit tip al functiei de eroare, implementata ca si hiperparametru in cadrul modelului. \n",
    "Spre exemplu modelul poate fii folosit cu functia de eroare liniara sau patratica. Acest lucru determina algoritmul sa se axeze mai mult sau mai putin pe corectarea valorilor aberante (outliers). \n",
    "<sup>\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor\">[6]</a>\n",
    "</sup>\n",
    "</h3>. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/GradientDescent.png\" >\n",
    "<p><center>Gradient Descent\n",
    "    <sup>\n",
    "        <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch04.html\">[4]</a>\n",
    "    </sup>\n",
    "    </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('machine-learning': conda)",
   "language": "python",
   "name": "python37664bitmachinelearningconda8c7742b76b4e4cbab872fad78a1b21c2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
